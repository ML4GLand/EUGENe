{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "ID = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x = torch.randn(10, 4, 100)\n",
    "x_rev_comp = torch.randn(10, 4, 100)\n",
    "y = torch.randint(0, 2, (10, 1))\n",
    "batch = (ID, x, x_rev_comp, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base import _layers as layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Exponential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exponential()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Conv1d(4, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(4, 8, kernel_size=(10,), stride=(1,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiConv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.BiConv1D(4, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiConv1D(4, 8, kernel_size=10, stride=1, padding=same, dilation=1, groups=1, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = torch.nn.Conv1d(4, 4, 10, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Residual(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 100])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 400])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4, 100])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.View((100, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscallaneous"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Clip(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base import _blocks as blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseBlock(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=200, bias=False)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Exponential()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=False)\n",
       "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Exponential()\n",
       "    (7): Linear(in_features=100, out_features=50, bias=False)\n",
       "    (8): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Exponential()\n",
       "    (10): Linear(in_features=50, out_features=10, bias=False)\n",
       "    (11): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Exponential()\n",
       "    (13): Linear(in_features=10, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_block = blocks.DenseBlock(\n",
    "    input_dim=400, \n",
    "    output_dim=1, \n",
    "    hidden_dims=[200, 100, 50, 10],\n",
    "    activations=\"exponential\",\n",
    "    batchnorm=True,\n",
    "    batchnorm_first=True, \n",
    "    dropout_rates=[0.1, None],\n",
    "    biases=False\n",
    ")\n",
    "dense_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9169],\n",
       "        [-1.0851],\n",
       "        [ 3.4325],\n",
       "        [-0.7624],\n",
       "        [-0.6778],\n",
       "        [-0.7515],\n",
       "        [-2.0970],\n",
       "        [-1.8601],\n",
       "        [-2.2710],\n",
       "        [-0.8283]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_block(x.reshape(10, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1DBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg', 'avg'] [<class 'torch.nn.modules.pooling.AvgPool1d'>, <class 'torch.nn.modules.pooling.AvgPool1d'>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv1DBlock(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv1d(4, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
       "    (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_block = blocks.Conv1DBlock(\n",
    "    input_len=100,\n",
    "    input_channels=4,\n",
    "    conv_channels=[10, 10],\n",
    "    conv_kernels=[3, 3],\n",
    "    conv_strides=[1, 1],\n",
    "    conv_dilations=[1, 1],\n",
    "    conv_padding=[\"valid\", \"valid\"],\n",
    "    activations=[None, \"relu\"],\n",
    "    pool_types=\"avg\",\n",
    "    pool_kernels=[1, 1],\n",
    "    pool_strides=[1, 1],\n",
    "    pool_padding=[0, 0],\n",
    "    dropout_rates=[None, 0.5],\n",
    "    batchnorm=True,\n",
    "    batchnorm_first=True\n",
    ")\n",
    "conv1d_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 96])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_block(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReccurentBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecurrentBlock(\n",
       "  (layers): LSTM(4, 10, num_layers=2, bias=False, batch_first=True, dropout=0.1, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrent_block = blocks.RecurrentBlock(\n",
    "    input_dim=4,\n",
    "    hidden_dim=10,\n",
    "    num_layers=2,\n",
    "    unit_type=\"lstm\",\n",
    "    bidirectional=True,\n",
    "    dropout_rates=0.1,\n",
    "    bias=False,\n",
    "    batch_first=True\n",
    ")\n",
    "recurrent_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 20])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrent_block(x.transpose(1, 2))[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiConv1DBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiConv1DBlock(\n",
       "  (kernels): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 10x4x3]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 10x10x3]\n",
       "  )\n",
       "  (biases): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 10]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 10]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biconv1d_block = blocks.BiConv1DBlock(\n",
    "    filters = 10,\n",
    "    kernel_size = 3,\n",
    "    layers = 2\n",
    ")\n",
    "biconv1d_block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Block (TODO: Is this more of a layer??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_block = blocks.TransformerBlock(\n",
    "    input_dim=4,\n",
    "    head_dim=10,\n",
    "    num_heads=2,\n",
    ")\n",
    "transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_block(x.transpose(1,2), mask=None).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:59:11.009011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "from eugene.models.base import _towers as towers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "from inspect import signature\n",
    "class MyBlock(torch.nn.Module):\n",
    "    def __init__(self, arg1: float, arg2: str, arg3: int = 42, arg4: str = 'default'):\n",
    "        super().__init__()\n",
    "        self.arg1 = arg1\n",
    "        self.arg2 = arg2\n",
    "        self.arg3 = arg3\n",
    "        self.arg4 = arg4\n",
    "    \n",
    "    def __repr__(self):\n",
    "        sig_vals = \", \".join([f'{arg}={getattr(self, arg)}' for arg in signature(self.__init__).parameters.keys()])\n",
    "        return f'MyBlock({sig_vals})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arg1': tensor(2., dtype=torch.float64), 'arg2': 'a', 'arg3': tensor(42)}\n",
      "{'arg1': tensor(2.2000, dtype=torch.float64), 'arg2': 'b', 'arg3': tensor(46)}\n",
      "{'arg1': tensor(2.4200, dtype=torch.float64), 'arg2': 'c', 'arg3': tensor(50)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tower(\n",
       "  (tower): Sequential(\n",
       "    (0): MyBlock(arg1=2.0, arg2=a, arg3=42, arg4=default)\n",
       "    (1): MyBlock(arg1=2.200000047683716, arg2=b, arg3=46, arg4=default)\n",
       "    (2): MyBlock(arg1=2.4200000762939453, arg2=c, arg3=50, arg4=default)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tower = towers.Tower(\n",
    "    block=MyBlock,\n",
    "    repeats=3,\n",
    "    dynamic_block_args={'arg1': 2, 'arg2': ['a', 'b', 'c']},\n",
    "    mults={'arg1': 1.1, 'arg3': 1.1}\n",
    ")\n",
    "my_tower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvTower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1DBlock(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv1d(4, 100, kernel_size=(10,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_block = blocks.Conv1DBlock(\n",
    "    input_len=100,\n",
    "    input_channels=4,\n",
    "    conv_channels=[100],\n",
    "    conv_kernels=[10],\n",
    "    conv_padding=\"same\"\n",
    ")\n",
    "conv1d_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_channels': 10}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'conv_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_70900/3792027368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv1d_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdynamic_block_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'conv_channels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/EUGENe/eugene/models/base/_towers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, repeats, static_block_args, dynamic_block_args, mults)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_block_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eugene/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'conv_channels'"
     ]
    }
   ],
   "source": [
    "towers.Tower(\n",
    "    block=conv1d_block,\n",
    "    repeats=3,\n",
    "    dynamic_block_args={'conv_channels': [10, 20, 30]},\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SequenceModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._base_models import SequenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `base._sequence_models.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._sequence_models import FCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (metric): R2Score()\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=400, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FCN(\n",
    "    input_len=100,\n",
    "    output_dim=10,\n",
    "    task=\"regression\",\n",
    "    optimizer=\"adam\",\n",
    "    dense_kwargs={\n",
    "        \"hidden_dims\": [50],\n",
    "        \"batchnorm\": True,\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._sequence_models import CNN\n",
    "from eugene.models.base._blocks import DenseBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    DenseBlock(input_dim=100, output_dim=100),\n",
    "    DenseBlock(input_dim=100, output_dim=100),\n",
    "    DenseBlock(input_dim=100, output_dim=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (2): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (metric): R2Score()\n",
       "  (conv1d_block): Conv1DBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "      (1): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    )\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=940, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(\n",
    "    input_len=100,\n",
    "    output_dim=10,\n",
    "    strand=\"ss\",\n",
    "    aggr=\"max\",\n",
    "    task=\"regression\",\n",
    "    optimizer=\"adam\",\n",
    "    conv_kwargs={\n",
    "        \"conv_channels\": [10, 10],\n",
    "        \"conv_kernels\": [5, 3],\n",
    "        \"activations\": [],\n",
    "        \"pool_types\": []\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from typing import Dict, Iterable, Callable\n",
    "\n",
    "#Define relevant classes and functions for feature extraction\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model: nn.Module, keyWord: str):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        layers = sorted([k for k in dict([*model.named_modules()]) if keyWord in k])\n",
    "        logging.info(\"{} model layers identified with key word {}\".format(len(layers), keyWord))\n",
    "        self.features = {layer: torch.empty(0) for layer in layers}\n",
    "        self.handles = dict() \n",
    "\n",
    "        for layerID in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layerID]\n",
    "            handle = layer.register_forward_hook(self.SaveOutputHook(layerID))\n",
    "            self.handles[layerID] = handle\n",
    "            \n",
    "    def SaveOutputHook(self, layerID: str) -> Callable:\n",
    "        def fn(laya, weValueYourInput, output): #laya = layer (e.g. Linear(...); weValueYourInput = input tensor\n",
    "            self.features[layerID] = output\n",
    "        return fn\n",
    "\n",
    "    def forward(self, x, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        preds = self.model(x, **kwargs)\n",
    "        return self.features, self.handles, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': CNN(\n",
       "   (metric): R2Score()\n",
       "   (conv1d_block): Conv1DBlock(\n",
       "     (layers): Sequential(\n",
       "       (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "       (1): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "     )\n",
       "   )\n",
       "   (dense_block): DenseBlock(\n",
       "     (layers): Sequential(\n",
       "       (0): Linear(in_features=940, out_features=10, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'metric': R2Score(),\n",
       " 'conv1d_block': Conv1DBlock(\n",
       "   (layers): Sequential(\n",
       "     (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "     (1): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "   )\n",
       " ),\n",
       " 'conv1d_block.layers': Sequential(\n",
       "   (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "   (1): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       " ),\n",
       " 'conv1d_block.layers.0': Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid),\n",
       " 'conv1d_block.layers.1': Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid),\n",
       " 'dense_block': DenseBlock(\n",
       "   (layers): Sequential(\n",
       "     (0): Linear(in_features=940, out_features=10, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'dense_block.layers': Sequential(\n",
       "   (0): Linear(in_features=940, out_features=10, bias=True)\n",
       " ),\n",
       " 'dense_block.layers.0': Linear(in_features=940, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([*model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extract = FeatureExtractor(model=model, keyWord=\"conv1d_block.layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 96])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_extract(x)[0][\"conv1d_block.layers.0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': CNN(\n",
       "   (metric): R2Score()\n",
       "   (conv1d_block): Conv1DBlock(\n",
       "     (layers): Sequential(\n",
       "       (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "       (1): ReLU()\n",
       "       (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "       (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "       (4): ReLU()\n",
       "       (5): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       "   (dense_block): DenseBlock(\n",
       "     (layers): Sequential(\n",
       "       (0): Linear(in_features=940, out_features=10, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'metric': R2Score(),\n",
       " 'conv1d_block': Conv1DBlock(\n",
       "   (layers): Sequential(\n",
       "     (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "     (4): ReLU()\n",
       "     (5): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       " ),\n",
       " 'conv1d_block.layers': Sequential(\n",
       "   (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "   (1): ReLU()\n",
       "   (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "   (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "   (4): ReLU()\n",
       "   (5): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " 'conv1d_block.layers.0': Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid),\n",
       " 'conv1d_block.layers.1': ReLU(),\n",
       " 'conv1d_block.layers.2': MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False),\n",
       " 'conv1d_block.layers.3': Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid),\n",
       " 'conv1d_block.layers.4': ReLU(),\n",
       " 'conv1d_block.layers.5': MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False),\n",
       " 'dense_block': DenseBlock(\n",
       "   (layers): Sequential(\n",
       "     (0): Linear(in_features=940, out_features=10, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'dense_block.layers': Sequential(\n",
       "   (0): Linear(in_features=940, out_features=10, bias=True)\n",
       " ),\n",
       " 'dense_block.layers.0': Linear(in_features=940, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([*model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x, x_rev_comp).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._sequence_models import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (metric): R2Score()\n",
       "  (recurrent_block): RecurrentBlock(\n",
       "    (layers): LSTM(4, 10, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(\n",
    "    input_len=100,\n",
    "    output_dim=10,\n",
    "    strand=\"ds\",\n",
    "    aggr=\"max\",\n",
    "    task=\"regression\",\n",
    "    optimizer=\"adam\",\n",
    "    recurrent_kwargs={\n",
    "        \"hidden_dim\": 10,\n",
    "        \"num_layers\": 2,\n",
    "        \"bidirectional\": True\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.transpose(1, 2), x_rev_comp.transpose(1, 2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._sequence_models import Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hybrid(\n",
       "  (metric): R2Score()\n",
       "  (conv1d_block): Conv1DBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (recurrent_block): RecurrentBlock(\n",
       "    (layers): LSTM(10, 10, num_layers=10, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Hybrid(\n",
    "    input_len=100,\n",
    "    output_dim=10,\n",
    "    strand=\"ss\",\n",
    "    aggr=\"max\",\n",
    "    task=\"regression\",\n",
    "    optimizer=\"adam\",\n",
    "    conv_kwargs={\n",
    "        \"conv_channels\": [10, 10],\n",
    "        \"conv_kernels\": [5, 3],\n",
    "        \"activations\": \"relu\",\n",
    "        \"pool_types\": \"max\"\n",
    "    },\n",
    "    recurrent_kwargs={\n",
    "        \"hidden_dim\": 10,\n",
    "        \"num_layers\": 10,\n",
    "        \"bidirectional\": True\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x, x_rev_comp).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_model_zoo.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TutorialCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import TutorialCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TutorialCNN(\n",
       "  (metric): R2Score()\n",
       "  (conv1): Conv1d(4, 30, kernel_size=(21,), stride=(1,))\n",
       "  (dense): Linear(in_features=30, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TutorialCNN(\n",
    "    input_len=100,\n",
    "    output_dim=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jores21CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import Jores21CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Jores21CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_73888/587963501.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Jores21CNN(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Jores21CNN' is not defined"
     ]
    }
   ],
   "source": [
    "model = Jores21CNN(\n",
    "    input_len=100,\n",
    "    output_dim=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kopp21CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import Kopp21CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Kopp21CNN(\n",
    "    input_len=100,\n",
    "    output_dim=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x, x_rev_comp).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactorizedBasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import FactorizedBasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FactorizedBasset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_73888/1172455722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFactorizedBasset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FactorizedBasset' is not defined"
     ]
    }
   ],
   "source": [
    "model = FactorizedBasset(input_len=100, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._blocks import Conv1DBlock\n",
    "from eugene.models.base._layers import Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_block = Conv1DBlock(\n",
    "    input_len=100,\n",
    "    input_channels=4,\n",
    "    conv_channels=[4],\n",
    "    conv_kernels=[10],\n",
    "    conv_padding=\"same\",\n",
    "    pool_types=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_block = Residual(conv1d_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 100])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_block(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import ResidualBind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResidualBind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_73888/2625957310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = ResidualBind(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ResidualBind' is not defined"
     ]
    }
   ],
   "source": [
    "model = ResidualBind(\n",
    "    input_len=100,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepBind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "2022-12-12 14:06:39.768074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "from eugene.models._model_zoo import DeepBind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepBind(\n",
    "    input_len=100,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import DeepSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgPool1d 4 1\n",
      "AvgPool1d 4 1\n",
      "MaxPool1d 4 1\n",
      "AvgPool1d 4 1\n",
      "MaxPool1d 4 1\n"
     ]
    }
   ],
   "source": [
    "model = DeepSEA(\n",
    "    input_len=100,\n",
    "    output_dim=1,\n",
    "    conv_kwargs={\n",
    "        \"pool_types\": [\"avg\", \"max\", None]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import Basset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Basset(\n",
    "    input_len=100,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DanQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import DanQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DanQ(\n",
    "    input_len=100,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/torch/nn/modules/conv.py:299: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSTARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._model_zoo import DeepSTARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSTARR(\n",
    "    input_len=100,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 120, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "\n",
    "class MyAccuracy(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds, target = self._input_format(preds, target)\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        self.correct += torch.sum(preds == target)\n",
    "        self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (MyAccuracy). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "metric = MyAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myaccuracy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.__class__.__name__.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base._sequence_models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of eugene.models failed: Traceback (most recent call last):\n",
      "  File \"/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/adamklie/miniconda3/envs/eugene/lib/python3.7/importlib/__init__.py\", line 160, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'eugene' not in sys.modules\n",
      "]\n",
      "Global seed set to 13\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_55788/2287247666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reduce_lr_on_plateau\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EUGENe/eugene/models/base/_sequence_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_len, output_dim, conv_kwargs, strand, task, aggr, loss_fxn, dense_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0minput_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mconv_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             )\n\u001b[1;32m    195\u001b[0m             self.dense_block = DenseBlock(\n",
      "\u001b[0;32m~/Desktop/EUGENe/eugene/models/base/_blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_len, input_channels, conv_channels, conv_kernels, conv_strides, conv_dilations, conv_padding, conv_biases, activations, pool_types, pool_kernels, pool_strides, pool_dilations, pool_padding, dropout_rates, batchnorm, batchnorm_first)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mbatchnorm_first\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     ):\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1DBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Define input parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = CNN(\n",
    "    input_len=100,\n",
    "    output_dim=1,\n",
    "    strand=\"ss\",\n",
    "    aggr=\"max\",\n",
    "    task=\"binary_classification\",\n",
    "    optimizer=\"adam\",\n",
    "    conv_kwargs={\n",
    "        \"conv_channels\": [10, 10],\n",
    "        \"conv_kernels\": [5, 3],\n",
    "        \"activations\": \"relu\",\n",
    "        \"pool_types\": \"max\"\n",
    "    },\n",
    "    scheduler=\"reduce_lr_on_plateau\",\n",
    "    metric=\"accuracy\",\n",
    "    seed=13\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'lr_scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7fbe3e911bd0>,\n",
       " 'monitor': 'val_loss'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lr_schedulers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_55788/2235029459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/eugene/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mlr_schedulers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mschedulers\u001b[0m \u001b[0mwere\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lr_schedulers'"
     ]
    }
   ],
   "source": [
    "model.lr_schedulers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.datasets._datasets import random1000\n",
    "from eugene.preprocess import ohe_seqs_sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqData object with = 1000 seqs\n",
       "seqs = (1000,)\n",
       "names = (1000,)\n",
       "rev_seqs = None\n",
       "ohe_seqs = None\n",
       "ohe_rev_seqs = None\n",
       "seqs_annot: 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_5', 'label_6', 'label_7', 'label_8', 'label_9', 'activity_0', 'activity_1', 'activity_2', 'activity_3', 'activity_4', 'activity_5', 'activity_6', 'activity_7', 'activity_8', 'activity_9'\n",
       "pos_annot: None\n",
       "seqsm: None\n",
       "uns: None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata = random1000()\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ce827101de4fdb9559c2b7264ace97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n"
     ]
    }
   ],
   "source": [
    "ohe_seqs_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    }
   ],
   "source": [
    "sdataset = sdata.to_dataset(target_keys=\"label_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdataloader = sdataset.to_dataloader(batch_size=128, shuffle=False)\n",
    "ID, x, x_rev_comp, y = next(iter(sdataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.5474207401275635, accuracy is 0.515625 at batch 0\n",
      "Loss is 0.5789369344711304, accuracy is 0.4765625 at batch 1\n",
      "Loss is 0.5303661823272705, accuracy is 0.5234375 at batch 2\n",
      "Loss is 0.6017324924468994, accuracy is 0.453125 at batch 3\n",
      "Loss is 0.5952660441398621, accuracy is 0.46875 at batch 4\n",
      "Loss is 0.5732230544090271, accuracy is 0.484375 at batch 5\n"
     ]
    }
   ],
   "source": [
    "model.metric.reset()\n",
    "metric_vals = []\n",
    "for batch_idx, batch in enumerate(sdataloader):\n",
    "    ID, x, x_rev_comp, y = batch\n",
    "    outs = model(x, x_rev_comp=None).squeeze(dim=1)\n",
    "    loss = model.loss_fxn(outs, y)\n",
    "    print(f\"Loss is {loss}\", end=\", \")\n",
    "    met = model.metric(outs, y.long())\n",
    "    print(f\"{model.metric_name} is {met} at batch {batch_idx}\")\n",
    "    metric_vals.append(met)\n",
    "    if batch_idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.mse_loss(input: torch.Tensor, target: torch.Tensor, size_average: Union[bool, NoneType] = None, reduce: Union[bool, NoneType] = None, reduction: str = 'mean') -> torch.Tensor>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Accuracy' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_53559/3963783885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eugene/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Accuracy' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "all_preds = torch.concat(model.metric.pred)\n",
    "all_targets = torch.concat(model.metric.target)\n",
    "binary_accuracy(all_preds, all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4870)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4870)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.Tensor(metric_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5029)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_metrics(probs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4725)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 100]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape, batch[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2946, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamklie/Desktop/EUGENe/eugene/models/base/_base_models.py:162: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = self.loss_fxn(outs, y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "log() missing 2 required positional arguments: 'name' and 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_53559/855973565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_common_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/EUGENe/eugene/models/base/_base_models.py\u001b[0m in \u001b[0;36m_common_step\u001b[0;34m(self, batch, batch_idx, optimizer_idx, stage)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mrank_zero_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Get and log metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: log() missing 2 required positional arguments: 'name' and 'value'"
     ]
    }
   ],
   "source": [
    "model._common_step(batch=batch, batch_idx=0, optimizer_idx=0, stage=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LightningModule.log_dict of CNN(\n",
       "  (metric): AUROC()\n",
       "  (conv1d_block): Conv1DBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(4, 10, kernel_size=(5,), stride=(1,), padding=valid)\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (dense_block): DenseBlock(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=940, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lr_schedulers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_55788/2235029459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/eugene/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mlr_schedulers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mschedulers\u001b[0m \u001b[0mwere\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lr_schedulers'"
     ]
    }
   ],
   "source": [
    "model.lr_schedulers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lr_schedulers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/f8q3_wcj5s98dwjv86bvq7hr0000gn/T/ipykernel_55788/2235029459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/eugene/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mlr_schedulers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mschedulers\u001b[0m \u001b[0mwere\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lr_schedulers'"
     ]
    }
   ],
   "source": [
    "model.lr_schedulers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene",
   "language": "python",
   "name": "eugene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7782186cff5d7e5d5e3fe0a7e6ebf1d74655b3470c460e9b06cf809b4e9601e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
