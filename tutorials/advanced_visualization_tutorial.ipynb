{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a88efe-ebb3-424c-8704-fb4ee189af2c",
   "metadata": {},
   "source": [
    "# Template for a EUGENe workflow on a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d058003-a667-4b45-9ddc-e47efe48e0e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *08/07/2022*\n",
    "***\n",
    "**Description:**\n",
    "Template notebook for creating a EUGENe workflow on a new dataset. To see a full list of functionality, check out the [API](https://eugenegroup.github.io/EUGENE/api/). You can always use `?` to see the available parameters for each method\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu\n",
    "\n",
    "# Configure EUGENe \n",
    "print(eu.__version__)\n",
    "eu.settings.dataset_dir = #TODO: path to dataset directory for saving download links\n",
    "eu.settings.logging_dir = #TODO: path to logging directory for model training logs\n",
    "eu.settings.output_dir = #TODO: path to output directory for outputs of model training\n",
    "eu.settings.dl_num_workers = #TODO: number of workers for data loading\n",
    "eu.settings.batch_size = #TODO: batch size for data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading\n",
    "We first need to load our data into memory. If the dataset is a \"EUGENe benchmarking dataset\", it can be loaded in through the `dataset` module:\n",
    "    \n",
    "```python\n",
    "eu.datasets.random1000()\n",
    "```\n",
    "\n",
    "If the requested dataset requires a download, it will be downloaded and loaded in automatically. Use `get_dataset_info()` to get information about the datasets available as \"EUGENe benchmarking datasets\".\n",
    "\n",
    "---\n",
    "\n",
    "You can also read from standard file formats into `SeqData` objects using `read_` functions from the `dataloading` module:\n",
    "\n",
    "```python\n",
    "eu.dl.read_csv('datasets/random1000/random1000_seqs.tsv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Data visualization is a key part of the EUGENe workflow. We can use the `plotting` module to visualize aspects of our dataset like target value distributions and sequence length:\n",
    "\n",
    "```python\n",
    "sdata[\"SEQ_LEN\"] = [len(seq) for seq in sdata.seqs]\n",
    "eu.pl.histplot(\n",
    "    sdata, \n",
    "    keys=\"SEQ_LEN\", \n",
    "    orient=\"h\"\n",
    ")\n",
    "eu.pl.violinplot(\n",
    "    sdata,\n",
    "    keys=\"target\",\n",
    "    groupby=\"group\",\n",
    "    hue=\"subgroup\",\n",
    "    xlab=\"Group\",\n",
    "    ylab=\"Target\",\n",
    "    title=\"Target distribution\"\n",
    ")\n",
    "```\n",
    "The above commands are examples that show the distribution of sequence lengths and the distribution of target values as a histogram and a violin plot respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write some code to visualize what your data looks like. eu.pl.histplot, eu.pl.boxplot, eu.pl.scatterplot, eu.pl.violinplot are useful functions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "We can preprocess our data using the `preprocessing` module. This includes:\n",
    "\n",
    "- reverse complementing sequences: ```eu.pp.reverse_complement_data(sdata)```\n",
    "- one hot encoding of the target values: ```eu.pp.one_hot_encode_data(sdata)```\n",
    "- training/validation/test split: ```eu.pp.train_test_split(sdata, split=0.8, rand_state=42)```\n",
    "- scaling the target values: ```eu.pp.scale_data(sdata)```\n",
    "- and more!\n",
    "\n",
    "Users are encouraged to take a look at the API for more functions you can use. Most users, however, can use the `eu.pp.prepare_data(sdata)` function to get there data ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Preprocess your sequences and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize after preprocessing to sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Now that we have our data ready, it's time to train our model. This starts with instantiating and initializing our model. We can use the `models` module to do this:\n",
    "\n",
    "```python\n",
    "model = eu.models.DeepBind(\n",
    "    input_len=100,\n",
    "    output_dim=1,\n",
    "    scheduler = \"reduce_lr_on_plateau\",\n",
    "    scheduler_patience=2,\n",
    "    lr=0.001\n",
    ")\n",
    "model.summary()\n",
    "eu.models.init_weights(model)\n",
    "```\n",
    "We offer several options for instantiating a model architecture. Take a look at the API for more options and details.\n",
    "- The `Base Model`s contain the 4 common base architectures: FCN, CNN, RNN and Hybrid. \n",
    "- The `SOTA Model`s contain 2 SOTA architectures: DeepBind and DeepSEA.\n",
    "- The `Custom Models` are models that you can add to. We have  a single custom model currently implemented to serve as a template (`Jores21CNN`). Who knows? Maybe your custom model will become SOTA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a model intantiated and initialized, we are set up to train our model. We can do this through the `train` module:\n",
    "\n",
    "```python\n",
    "eu.train.fit(\n",
    "    model=model, \n",
    "    sdata=sdata, \n",
    "    gpus=1, \n",
    "    target=\"target\",\n",
    "    train_key=\"train\",\n",
    "    epochs=50,\n",
    "    version=f\"v1\"\n",
    ")\n",
    "```\n",
    "\n",
    "We can see how well our models trained by plotting a training summary:\n",
    "\n",
    "```python\n",
    "eu.train.pl_training_summary(model_leaf, version=f\"v1\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize your models parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "After the model's been trained, we can evaluate our performance on our training data and our held-out test data. This is done through the `plotting` module.\n",
    "It is often best to use the model that achieved the lowest loss on the validation data for evaluation. We can load this model in from the log directory:\n",
    "```python\n",
    "best_model = eu.models.DeepBind.load_from_checkpoint(\"...\")\n",
    "```\n",
    "We can then use this model to make predictions on our training and validation data and to visualize the performance:\n",
    "```python\n",
    "eu.predict.train_val_predictions(\n",
    "    best_model, \n",
    "    sdata=sdata, \n",
    "    target=\"target\",\n",
    "    train_key=\"train\",\n",
    "    version=f\"v1\",\n",
    ")\n",
    "train_idx = np.where(sdata_leaf_train[\"train\"] == True)[0]\n",
    "eu.pl.performance_scatter(\n",
    "    sdata, \n",
    "    seq_idx=train_idx, \n",
    "    target=\"target\", \n",
    "    prediction=\"target_predictions\",\n",
    "    title=\"Training Set Performance\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: See how you performed and the training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand how the model is performing on a held-out (and ideally independent) test set. You should either load this separately above, here or have split your data up in preprocessing (see `jores21_analysis.ipynb` for an example).\n",
    "\n",
    "```python\n",
    "eu.predict.predictions(\n",
    "    best_model, \n",
    "    sdata=sdata, \n",
    "    target=\"target\",\n",
    "    version=f\"v1\",\n",
    "    file_label=\"test\"\n",
    ")\n",
    "eu.predict.predictions(\n",
    "    best_model, \n",
    "    sdata=sdata, \n",
    "    target=\"target\",\n",
    "    version=f\"v1\",\n",
    "    file_label=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If you have a test set, see how you did on that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "Potentially the most important step in the EUGENe workflow is the interpretation of the model's predictions. This is done through the `interpret` module. All the functions in this module act on either `SeqData` and Models or just Models. Results from these calls can be visualized using the `plotting` module.\n",
    "---\n",
    "There are many options for interpreting the model's predictions, and we will again point users to the API for all the options and their arguments. We list examples for a few common ones below.\n",
    "\n",
    "\n",
    "```python\n",
    "eu.interpret.generate_pfms(\n",
    "    best_model_leaf, \n",
    "    sdata_leaf_test\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature attribution\n",
    "We can calculate the contribution of each nucleotide to the model's predictions for a sequence by using the `interpret` module's `feature_attribution` function. We currently implement several different methods for this, includeing `DeepLift, ISM, InputXGradient and DeepSHAP`.\n",
    "```python\n",
    "eu.interpret.feature_attribution(\n",
    "    best_model,\n",
    "    sdata_test,\n",
    "    saliency_method=\"DeepLift\",\n",
    "    device= \"cuda\" if eu.settings.gpus > 0 else \"cpu\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run feature attribution on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Visualization \n",
    "We can get an idea for what each filter of first convoulional layer of the model is seeing by using the `interpret` module's `generate_pfms` function. This creates a position frequency matrix for each filter in the model using sequences that highly activate that filter (can be defined in multiple ways). We often times pass the the test sequences through the model, but you can theoretically pass any sequences you want.\n",
    "```python\n",
    "eu.interpret.generate_pfms(\n",
    "    best_model, \n",
    "    sdata_test\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run filter visualization on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other intepretation methods\n",
    "We currently implement a few other methods for interpreting the model's predictions. These include:\n",
    "- Dimensionality Reduction on your importance scores: e.g. `eu.interpret.pca`\n",
    "- ...\n",
    "We are looking to add more! If you are interested in contributing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform other intepretation methods on your trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up\n",
    "EUGENe is very much meant to be a community project. It represents a collection of data, models, and techniques meant for analyzing sequence data with deep learning. We are looking for contributions in almost every aspect of EUGENe. We are particularly interested in:\n",
    "\n",
    "- New model additions through the `models` module\n",
    "- New dataset additions through the `datasets` module\n",
    "- New preprocessing techniques through the `preprocessing` module\n",
    "- New visualization techniques through the `plotting` module\n",
    "- New interpretation techniques through the `interpret` module\n",
    "- New methods for training models in the `train` module\n",
    "\n",
    "Please do not hesitate to contact us if you have any questions or suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
