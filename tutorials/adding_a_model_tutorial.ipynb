{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a88efe-ebb3-424c-8704-fb4ee189af2c",
   "metadata": {},
   "source": [
    "# Adding a model to EUGENe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d058003-a667-4b45-9ddc-e47efe48e0e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *10/05/2022*\n",
    "***\n",
    "**Description:**\n",
    "This tutorial is intended to show how to add a model to EUGENe. It's a pretty simple process, but it's important to follow the steps in order to ensure that the model can be properly utiilized properly throughout the EUGENe pipeline.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu\n",
    "\n",
    "eu.settings.dataset_dir = \"./tutorial_datasets\"\n",
    "eu.settings.logging_dir = \"./tutorial_logs\"\n",
    "eu.settings.output_dir = \"./tutorial_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Review the `BaseModel` class and check out some examples in the `_custom_models.py` file\n",
    "In order to fully integrate models into the EUGENe pipeline, it is recommended that you make your model a subclass of the [`BaseModel` class]() (**TODO**). Though many of EUGENe's functions work under the assumption that the model is a subclass of a `torch.nn.Module`, many other functions assume a structure dictated by the `BaseModel` class. For the rest of this tutorial, we assume that we are inheriting from `BaseModel`.\n",
    "\n",
    "Before you begin implementing anything it is recommended that you take a look at the `BaseModel` class attributes. These are the attributes that you will need to instantiate for any EUGENe model. I also find that it helps to see a few examples, which you can find in the `_custom_models.py` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a model class\n",
    "* This should be a Python class that at the very least inherets from torch.nn.Module, but ideally should inherit from the `BaseModel` class.\n",
    "    - If your model is associated with a publication, use the last name of the first author followed by the year of publication (NameYY). It can also be useful to add the type of model you are implementing. For example, if the model is a CNN that was published in 2021 by the author \"Jane Doe\", the function should be named `Doe21CNN`. \n",
    "* At the minimum, this class should have two functions an  `__init__` and a `forward`\n",
    "    - `__init__`\n",
    "        * Needs to call:\n",
    "        ```python\n",
    "        super().__init__(\n",
    "            input_len, \n",
    "            output_dim, \n",
    "            strand=strand, \n",
    "            task=task, \n",
    "            aggr=aggr, \n",
    "            loss_fxn=loss_fxn,\n",
    "            **kwargs\n",
    "        )\n",
    "        ```\n",
    "    - `forward`\n",
    "        * Needs to take in x and x_rev as arguments with x_rev defaulting to None. Even if your model takes in only the forward strand (i.e. does not use \"ds\" or \"ts\" modes), this needs to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from eugene.models.base import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(BaseModel):\n",
    "\n",
    "def __init__(\n",
    "        self,\n",
    "        input_len: int,\n",
    "        output_dim: int,\n",
    "        strand: str = \"ss\",\n",
    "        task: str = \"regression\",\n",
    "        aggr: str = None,\n",
    "        loss_fxn: str = \"mse\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Don't worry that we don't pass in the class name to the super call (as is standard for creating new\n",
    "        # nn.Module subclasses). This is handled by inherting BaseModel\n",
    "        super().__init__(\n",
    "            input_len, \n",
    "            output_dim, \n",
    "            strand=strand, \n",
    "            task=task, \n",
    "            aggr=aggr, \n",
    "            loss_fxn=loss_fxn,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "def forward(self, x, x_rev_comp=None):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test the forward pass\n",
    "Its often helpful to run a simple forward pass of the model with some dummy data to make sure all your matrix multiplication and other operations are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of strand\n",
    "x_len = 66\n",
    "\n",
    "# Generate some random input\n",
    "x = torch.randn(10, 4, x_len)\n",
    "x_rev = torch.randn(10, 4, x_len)\n",
    "y = torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your model\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x, x_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test a PL trainer\n",
    "If your model is a BaseModel instance and you are working with SeqData objects, this is as simple as a call to the `fit` function within the `train` model.\n",
    "\n",
    "If you are working directly with PL trainers, this is a little more complicated but still not too bad! You just need to create an appropriate DataLoader for your implementation (which can be converted form a SeqData object) and pass the model and the dataloader to a PL trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `train.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = eu.datasets.random1000()\n",
    "eu.train.fit(sdata, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly using PL trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdataloader = DataLoader(sdata.to_dataset(target_keys=\"activity_0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, sdataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Adding you model to EUGENe\n",
    "Once you are happy with how your model seems to be working, you can add it to the appropriate `.py` file within EUGENe. \n",
    "- `_base_models.py`: This is meant for implementations of flexible architectures that are at the core of deep learning across fields. This might be something like a vanilla autoencoder, where you can change the number of hidden layers and units in the encoder or decoder.\n",
    "- `_sota_models.py`: These are often times instances of the the above Base Models. Often these models have architectures that don't quite fit within the mold of the Base Models (e.g. DeepBind models that concatenate global and average pooling layers), but can also just be calls to Base Models with a specific configuration of hyperparameters (an example of the latter might be the DeepSEA architecture, which could be created with a specific call to a CNN). There also must be some basis for calling this a SOTA architecture. I realize this is somewhat arbitrary and I could probably have endless debates with people about what this means, but I typically use the rule that I know a SOTA architecture when I see one (e.g. if you are reading this you probably know what DeepSEA is).\n",
    "- `_custom_models.py`: These are custom architectures that don't really fall under the Base Models or SOTA Models. These might be published models that were successful on a particular dataset, or your own custom architecture you just want to be able to use within EUGENe. A note for the latter. In order for the a custom model to make it into a future release of EUGENe, there should be some basis for its inclusion. That is you should be able to demonstrate the utility of the architecure on some real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create a unit test for your model\n",
    "* In order for your model to make it into the next EUGENe release, it needs to have a unit test within the [`test_models.py` file](TODO). At a minimum this unit test should test the instantiation of your model and the training procedure of your choice on some dummy data. Check out the unit tests already there for more examples.\n",
    "\n",
    "As is the general rule for testing, the more \"units\" you can test the better. Feel free to add other tests as well. One other area that might be a little tricky is making sure the convolutional filters of your model are seen by the `generate_pfms` function in the `interpret` module. \n",
    "\n",
    "Don't forget to actually run your tests as well! This can be done with the following command\n",
    "\n",
    "```bash\n",
    "pytest tests/test_models.py -k \"test_NewModelCNN21.py\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Document your function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your happy with your model, you've tested it and it's working as expected, you can add documentation to the function. This is done by adding a docstring to the function. The docstring should be formatted in numpydoc format and should contain a parameters and a returns section. You can see examples of this in the any of the model's scripts.\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Reads in the farley15 dataset.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "return_sdata : bool, optional\n",
    "    If True, return SeqData object for the farley15 dataset. The default is True.\n",
    "    If False, return the paths to any downloaded files.\n",
    "**kwargs : kwargs, dict\n",
    "    Keyword arguments to pass to read_csv.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "sdata : SeqData\n",
    "    SeqData object for the farley15 dataset.\n",
    "\"\"\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Add information to the EUGENe model Notion database\n",
    "If you want to help me in my never ending quest/addiction to organize things, please consider adding the details of your new model to [this](TODO) Notion database. Check out the example already there for how to format your entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. (Optional) Submit a pull request\n",
    "You only need to do this if you want to share your model with the world (which is strongly encouraged)!\n",
    "\n",
    "Once you've completed all of the above steps, you can submit a pull request to the EUGENe repository. We will review your pull request and merge it into the main branch if everything looks good. If there are any issues, we will let you know and you can make the necessary changes. Once your pull request is merged, your model will be available in the next release of EUGENe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X. More advanced training techniques\n",
    "- Use supplementary note stuff\n",
    "- Note that tutorials for this are coming!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up\n",
    "Hopefully this guide was helpful in getting you started with adding your own model to EUGENe. If you have any questions, feel free to open a GitHub issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
