{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661f6b58",
   "metadata": {},
   "source": [
    "# Testing `ResidualBind` model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64213c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *11/05/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook for testing out the custom `ResidualBind` model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base import BasicConv1D\n",
    "class ResidualModule(nn.Module):\n",
    "    \"\"\"Generates a PyTorch module with the residual binding architecture described in:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_len : int\n",
    "        Length of the input sequence\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_len, \n",
    "        channels, \n",
    "        conv_kernels, \n",
    "        conv_strides,\n",
    "        dilations, \n",
    "        pool_kernels=None, \n",
    "        activation=\"relu\", \n",
    "        pool_strides=None, \n",
    "        dropout_rates=0.0, \n",
    "        padding=\"same\", \n",
    "        batchnorm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.module = BasicConv1D(\n",
    "            input_len=input_len,\n",
    "            channels=channels,\n",
    "            conv_kernels=conv_kernels,\n",
    "            conv_strides=conv_strides,\n",
    "            pool_kernels=pool_kernels,\n",
    "            activation=activation,\n",
    "            pool_strides=pool_strides,\n",
    "            dropout_rates=dropout_rates,\n",
    "            dilations=dilations,\n",
    "            padding=padding,\n",
    "            batchnorm=batchnorm\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fwd = self.module(x)\n",
    "        return F.relu(x_fwd + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualModule(\n",
       "  (module): BasicConv1D(\n",
       "    (module): Sequential(\n",
       "      (0): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
       "      (5): ReLU()\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
       "      (9): ReLU()\n",
       "      (10): Dropout(p=0.1, inplace=False)\n",
       "      (11): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResidualModule(\n",
    "    input_len=100,\n",
    "    channels=[96, 96, 96, 96],\n",
    "    conv_kernels=[3, 3, 3],\n",
    "    conv_strides=[1, 1, 1],\n",
    "    dilations=[1, 2, 4],\n",
    "    dropout_rates=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base import BaseModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from eugene.models.base._utils import GetFlattenDim\n",
    "from eugene.models.base import BasicFullyConnectedModule\n",
    "\n",
    "class ResidualBind(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_len,\n",
    "        output_dim,\n",
    "        strand=\"ss\",\n",
    "        task=\"regression\",\n",
    "        aggr=None,\n",
    "        conv_channels=[96],\n",
    "        conv_kernel_size=[11],\n",
    "        conv_stride_size=[1],\n",
    "        conv_dilation_rate=[1],\n",
    "        conv_padding=\"same\",\n",
    "        conv_activation=\"relu\",\n",
    "        conv_batchnorm=True,\n",
    "        conv_dropout=0.1,\n",
    "        residual_channels=[3, 3, 3],\n",
    "        residual_kernel_size=[11, 11, 11],\n",
    "        residual_stride_size=[1, 1, 1],\n",
    "        residual_dilation_rate=[1, 1, 1],\n",
    "        residual_padding=\"same\",\n",
    "        residual_activation=\"relu\",\n",
    "        residual_batchnorm=True,\n",
    "        residual_dropout=0.1,\n",
    "        pool_kernel_size=10,\n",
    "        pool_dropout=0.2,\n",
    "        fc_hidden_dims=[256],\n",
    "        fc_activation=\"relu\",\n",
    "        fc_batchnorm=True,\n",
    "        fc_dropout=0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            input_len, output_dim, strand=strand, task=task, aggr=aggr, **kwargs\n",
    "        )\n",
    "        if isinstance(conv_channels, int):\n",
    "            conv_channels = [conv_channels]\n",
    "        self.conv = BasicConv1D(\n",
    "            input_len=input_len,\n",
    "            channels=[4] + conv_channels,\n",
    "            conv_kernels=conv_kernel_size,\n",
    "            conv_strides=conv_stride_size,\n",
    "            pool_kernels=None,\n",
    "            activation=conv_activation,\n",
    "            pool_strides=None,\n",
    "            dropout_rates=conv_dropout,\n",
    "            dilations=conv_dilation_rate,\n",
    "            padding=conv_padding,\n",
    "            batchnorm=conv_batchnorm\n",
    "        )\n",
    "        res_block_input_len = GetFlattenDim(self.conv.module, seq_len=input_len)\n",
    "        self.residual_block = ResidualModule(\n",
    "            input_len=res_block_input_len,\n",
    "            channels=[self.conv.out_channels] + residual_channels,\n",
    "            conv_kernels=residual_kernel_size,\n",
    "            conv_strides=residual_stride_size,\n",
    "            pool_kernels=None,\n",
    "            activation=residual_activation,\n",
    "            pool_strides=None,\n",
    "            dropout_rates=residual_dropout,\n",
    "            dilations=residual_dilation_rate,\n",
    "            padding=residual_padding,\n",
    "            batchnorm=residual_batchnorm\n",
    "        )\n",
    "        self.average_pool = nn.AvgPool1d(pool_kernel_size, stride=1)\n",
    "        self.dropout = nn.Dropout(pool_dropout)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = BasicFullyConnectedModule(\n",
    "            input_dim=self.residual_block.module.out_channels*(res_block_input_len-pool_kernel_size+1),\n",
    "            output_dim=output_dim,\n",
    "            hidden_dims=fc_hidden_dims,\n",
    "            activation=fc_activation,\n",
    "            batchnorm=fc_batchnorm,\n",
    "            dropout_rate=fc_dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_rev):\n",
    "        x = self.conv(x)\n",
    "        x = self.residual_block(x)\n",
    "        x = self.average_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualBind(\n",
       "  (hp_metric): R2Score()\n",
       "  (conv): BasicConv1D(\n",
       "    (module): Sequential(\n",
       "      (0): Conv1d(4, 96, kernel_size=(11,), stride=(1,), padding=valid)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (residual_block): ResidualModule(\n",
       "    (module): BasicConv1D(\n",
       "      (module): Sequential(\n",
       "        (0): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
       "        (5): ReLU()\n",
       "        (6): Dropout(p=0.1, inplace=False)\n",
       "        (7): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
       "        (9): ReLU()\n",
       "        (10): Dropout(p=0.1, inplace=False)\n",
       "        (11): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (average_pool): AvgPool1d(kernel_size=(10,), stride=(1,), padding=(0,))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): BasicFullyConnectedModule(\n",
       "    (module): Sequential(\n",
       "      (0): Linear(in_features=7776, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResidualBind(\n",
    "    input_len=100,\n",
    "    output_dim=1,\n",
    "    conv_channels=[96],\n",
    "    conv_kernel_size=[11],\n",
    "    conv_stride_size=[1],\n",
    "    conv_dilation_rate=[1],\n",
    "    conv_padding=\"valid\",\n",
    "    conv_activation=\"relu\",\n",
    "    conv_batchnorm=True,\n",
    "    conv_dropout=0.1,\n",
    "    residual_channels=[96, 96, 96],\n",
    "    residual_kernel_size=[3, 3, 3],\n",
    "    residual_stride_size=[1, 1, 1],\n",
    "    residual_dilation_rate=[1, 2, 4],\n",
    "    residual_padding=\"same\",\n",
    "    residual_activation=\"relu\",\n",
    "    residual_batchnorm=True,\n",
    "    residual_dropout=0.1,\n",
    "    pool_dropout=0.2,\n",
    "    fc_hidden_dims=[256],\n",
    "    fc_activation=\"relu\",\n",
    "    fc_batchnorm=True,\n",
    "    fc_dropout=0.5,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3461],\n",
       "        [-0.3445],\n",
       "        [-0.2476],\n",
       "        [-0.3241],\n",
       "        [ 0.2127],\n",
       "        [-0.0573],\n",
       "        [ 0.3616],\n",
       "        [-0.1408],\n",
       "        [ 0.3614],\n",
       "        [-0.1719]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 4, 100)\n",
    "model(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b89b94102a47d3a29709cf5f5a8de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n",
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + train_val\n"
     ]
    }
   ],
   "source": [
    "sdata = eu.datasets.random1000()\n",
    "eu.pp.ohe_seqs_sdata(sdata)\n",
    "eu.pp.train_test_split_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "Missing logger folder: /workspaces/EUGENe/tests/notebooks/implement/models/eugene_logs/ssResidualBind_regression\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type                      | Params\n",
      "-------------------------------------------------------------\n",
      "0 | hp_metric      | R2Score                   | 0     \n",
      "1 | conv           | BasicConv1D               | 4.5 K \n",
      "2 | residual_block | ResidualModule            | 83.8 K\n",
      "3 | average_pool   | AvgPool1d                 | 0     \n",
      "4 | dropout        | Dropout                   | 0     \n",
      "5 | flatten        | Flatten                   | 0     \n",
      "6 | fc             | BasicFullyConnectedModule | 2.0 M \n",
      "-------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.320     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15103dc447749308845d19db0efb48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 13\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be41c66e0c334c92a7ae592ab87011c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a7e9ff522f4e0c9760a547f1ca3254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eu.train.fit(model, sdata, target_keys=\"activity_0\", epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
