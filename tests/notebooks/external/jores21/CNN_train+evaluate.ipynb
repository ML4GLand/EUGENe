{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a convolutional neural network to predict promoter strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 14:47:48.071689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow.keras.layers as kl\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from io import TextIOBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable GPU memory growth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 14:48:46.664825: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-30 14:48:46.673904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-30 14:48:46.706929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-30 14:48:46.708094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:c3:00.0 name: Quadro RTX 5000 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-07-30 14:48:46.708115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-30 14:48:46.760757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-30 14:48:46.760803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-30 14:48:46.783777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-30 14:48:46.793947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-30 14:48:46.832502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-30 14:48:46.841591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-30 14:48:46.908411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-30 14:48:46.908640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so retur"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to one-hot encode the DNA sequences (adapted from https://colab.research.google.com/drive/17E4h5aAOioh5DiTo7MZg4hpL6Z_0FyWr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "integer_encoder = LabelEncoder()  \n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "\n",
    "def one_hot_encoding(sequences, verbose = True): \n",
    "    one_hot_sequences = []\n",
    "\n",
    "    if verbose:\n",
    "        i = 0\n",
    "        print('one-hot encoding in progress ...', flush = True)\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "        integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "        one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "        one_hot_sequences.append(one_hot_encoded.toarray())\n",
    "    \n",
    "        if verbose:\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i, 'sequences processed', flush = True, end = '\\r')\n",
    "        \n",
    "    if verbose:\n",
    "        print('finished one-hot encoding:', i, 'sequences processed', flush = True)\n",
    "    \n",
    "    one_hot_sequences = np.stack(one_hot_sequences)\n",
    "\n",
    "    return one_hot_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to read in MEME files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Motif:\n",
    "    identifier: str\n",
    "    pfm: np.ndarray\n",
    "    alphabet_length: int\n",
    "    length: int\n",
    "    name: Optional[str] = None\n",
    "    source_sites: Optional[int] = None\n",
    "    source_evalue: Optional[float] = None\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "    \n",
    "    \n",
    "class MinimalMEME:\n",
    "    \"\"\" http://meme-suite.org/doc/meme-format.html \"\"\"\n",
    "    \n",
    "    __version_regex = re.compile('^MEME version ([0-9]+)$')\n",
    "    __background_regex = re.compile('^Background letter frequencies(?: \\(from (.+)\\))?$')\n",
    "    __background_sum_error = 0.00001\n",
    "    __pfm_header_regex = re.compile('^letter-probability matrix:(?: alength= ([0-9]+))?(?: w= ([0-9]+))?(?: nsites= ([0-9]+))?(?: E= ([0-9.e-]+))?$')\n",
    "    version = None\n",
    "    alphabet = None\n",
    "    strands = None\n",
    "    background = None\n",
    "    background_source = None\n",
    "    motifs = None\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.motifs = {}\n",
    "        \n",
    "        # parse the minimal MEME file\n",
    "        with open(path) as minimal_meme_file:\n",
    "            line = minimal_meme_file.readline()\n",
    "            # first line must be version\n",
    "            self.version = self._parse_version(line)\n",
    "\n",
    "            line = minimal_meme_file.readline()\n",
    "            while line:\n",
    "                if line.startswith('ALPHABET'):\n",
    "                    if self.alphabet is None:\n",
    "                        self.alphabet = self._parse_alphabet(line)\n",
    "                        line = minimal_meme_file.readline()\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple alphabet definitions encountered in MEME file\")\n",
    "                elif line.startswith('strands: '):\n",
    "                    if self.strands is None:\n",
    "                        self.strands = self._parse_strands(line)\n",
    "                        line = minimal_meme_file.readline()\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple strand definitions encountered in MEME file\")\n",
    "                elif line.startswith('Background letter frequencies'):\n",
    "                    if self.background is None:\n",
    "                        line = self._parse_background(line, minimal_meme_file)\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple background frequency definitions encountered in MEME file\")\n",
    "                elif line.startswith('MOTIF'):\n",
    "                    line = self._parse_motif(line, minimal_meme_file)\n",
    "                else:\n",
    "                    line = minimal_meme_file.readline()\n",
    "    \n",
    "    def _parse_version(self, line: str) -> str:\n",
    "        match = re.match(self.__version_regex, line)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Minimal MEME file missing version string on first line\")\n",
    "            \n",
    "    def _parse_alphabet(self, line: str) -> str:\n",
    "        if line.startswith('ALPHABET '):\n",
    "            raise NotImplementedError(\"Alphabet definitions not supported\")\n",
    "        elif line.startswith('ALPHABET= '):\n",
    "            return line.rstrip()[10:]\n",
    "        else:\n",
    "            raise RuntimeError('Unable to parse alphabet line')\n",
    "            \n",
    "    def _parse_strands(self, line: str) -> str:\n",
    "        strands = line.rstrip()[9:]\n",
    "        if not ((strands == '+') or (strands == '+ -')):\n",
    "            raise RuntimeError(\"Invalid strand specification\")\n",
    "        else:\n",
    "            return strands\n",
    "        \n",
    "    def _parse_background(self, line: str, handle: TextIOBase) -> str:\n",
    "        match = re.match(self.__background_regex, line)\n",
    "        if match:\n",
    "            if match.group(1) is not None:\n",
    "                self.background_source = match.group(1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unable to parse background frequency line\")\n",
    "\n",
    "        self.background = {}\n",
    "        # start parsing possibly multiple lines of background frequencies\n",
    "        line = handle.readline()\n",
    "        while line:\n",
    "            if (not line.rstrip()) or line.startswith('MOTIF'):\n",
    "                if abs(1 - sum(self.background.values())) <= self.__background_sum_error:\n",
    "                    return line\n",
    "                else:\n",
    "                    raise RuntimeError(\"Background frequencies do not sum to 1\")\n",
    "            else:\n",
    "                line_freqs = line.rstrip().split(' ')\n",
    "                if len(line_freqs) % 2 != 0:\n",
    "                    raise RuntimeError(\"Invalid background frequency definition\")\n",
    "                for residue, freq in zip(line_freqs[0::2], line_freqs[1::2]):\n",
    "                    self.background[residue] = float(freq)\n",
    "            line = handle.readline()\n",
    "    \n",
    "    def _parse_motif(self, line: str, handle: TextIOBase) -> str:\n",
    "        # parse motif identifier\n",
    "        line_split = line.rstrip().split(' ')\n",
    "        if (len(line_split) < 2) or (len(line_split) > 3):\n",
    "            raise RuntimeError(\"Invalid motif name line\")\n",
    "        motif_identifier = line_split[1]\n",
    "        motif_name = line_split[2] if len(line_split) == 3 else None\n",
    "        \n",
    "        line = handle.readline()\n",
    "        # parse letter probability matrix header\n",
    "        if not line.startswith('letter-probability matrix:'):\n",
    "            raise RuntimeError(\"No letter-probability matrix header line in motif entry\")\n",
    "        match = re.match(self.__pfm_header_regex, line)\n",
    "        if match:\n",
    "            motif_alphabet_length = int(match.group(1)) if match.group(1) is not None else None\n",
    "            motif_length = int(match.group(2)) if match.group(2) is not None else None\n",
    "            motif_source_sites = int(match.group(3)) if match.group(3) is not None else None\n",
    "            motif_source_evalue = float(match.group(4)) if match.group(4) is not None else None\n",
    "        else:\n",
    "            raise RuntimeError(\"Unable to parse letter-probability matrix header\")\n",
    "        \n",
    "        # parse letter probability matrix\n",
    "        line = handle.readline()\n",
    "        pfm_rows = []\n",
    "        while line:\n",
    "            if (not line.rstrip()) or line.startswith('MOTIF'):\n",
    "                if motif_identifier in self.motifs:\n",
    "                    raise RuntimeError(\"Motif identifiers not unique within file\")\n",
    "                pfm = np.stack(pfm_rows)\n",
    "                if motif_length is None:\n",
    "                    motif_length = pfm.shape[0]\n",
    "                elif motif_length != pfm.shape[0]:\n",
    "                    raise RuntimeError(\"Provided motif length is not consistent with the letter-probability matrix shape\")\n",
    "                self.motifs[motif_identifier] = Motif(\n",
    "                    identifier = motif_identifier,\n",
    "                    pfm = pfm,\n",
    "                    alphabet_length = motif_alphabet_length,\n",
    "                    length = motif_length,\n",
    "                    name = motif_name,\n",
    "                    source_sites = motif_source_sites,\n",
    "                    source_evalue = motif_source_evalue\n",
    "                )\n",
    "                return line\n",
    "            else:\n",
    "                line_split = line.rstrip().split()\n",
    "                if motif_alphabet_length is None:\n",
    "                    motif_alphabet_length = len(line_split)\n",
    "                elif motif_alphabet_length != len(line_split):\n",
    "                    raise RuntimeError(\"Letter-probability matrix row length doesn't equal alphabet length\")\n",
    "                pfm_row = np.array([float(s) for s in line_split])\n",
    "                pfm_rows.append(pfm_row)\n",
    "                line = handle.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert the data to the required format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CPE and TF motifs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "core_promoter_elements = MinimalMEME('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/CPEs.meme')\n",
    "tf_groups = MinimalMEME('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/TF-clusters.meme')\n",
    "all_motifs = {**core_promoter_elements.motifs, **tf_groups.motifs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_test_leaf = pd.read_csv('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/CNN_test_leaf.tsv', sep = '\\t', header = 0)\n",
    "data_train_leaf = pd.read_csv('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/CNN_train_leaf.tsv', sep = '\\t', header = 0)\n",
    "data_test_proto = pd.read_csv('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/CNN_test_proto.tsv', sep = '\\t', header = 0)\n",
    "data_train_proto = pd.read_csv('/cellar/users/aklie/projects/EUGENe/tests/_data/datasets/jores21/CNN_train_proto.tsv', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the promoter sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 65004 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 7154 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 68213 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 7595 sequences processed\n"
     ]
    }
   ],
   "source": [
    "train_sequences_leaf = one_hot_encoding(data_train_leaf['sequence'])\n",
    "test_sequences_leaf = one_hot_encoding(data_test_leaf['sequence'])\n",
    "train_sequences_proto = one_hot_encoding(data_train_proto['sequence'])\n",
    "test_sequences_proto = one_hot_encoding(data_test_proto['sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the enrichment value to an array of the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_enrichment_leaf = np.array(data_train_leaf['enrichment']).reshape(-1, 1)\n",
    "test_enrichment_leaf = np.array(data_test_leaf['enrichment']).reshape(-1, 1)\n",
    "train_enrichment_proto = np.array(data_train_proto['enrichment']).reshape(-1, 1)\n",
    "test_enrichment_proto = np.array(data_test_proto['enrichment']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a bidirectional convolutional layer stack, inspired from DeepGMAP (https://doi.org/10.1371/journal.pone.0235748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class BiConv1D(kl.Layer):\n",
    "    def __init__(self, filters, kernel_size, layers = 2, stride = 1, dropout_rate = 0.15):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        if layers < 1:\n",
    "            raise ValueError(\"At least one layer needed\")\n",
    "        self.layers = layers\n",
    "        if (dropout_rate < 0) or (dropout_rate > 1):\n",
    "            raise ValueError(\"Dropout rate must be a float between 0 and 1\")\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernels = []\n",
    "        self.biases = []\n",
    "        for layer in range(self.layers):\n",
    "            self.kernels.append(self.add_weight(\n",
    "                f\"kernel{layer}\",\n",
    "                shape = (self.kernel_size, input_shape[-1], self.filters),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.GlorotUniform()\n",
    "            ))\n",
    "            self.biases.append(self.add_weight(\n",
    "                f\"bias{layer}\",\n",
    "                shape = (self.filters,),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.Zeros()\n",
    "            ))\n",
    "        print(self.kernels[0].shape, self.kernels[1].shape)\n",
    "\n",
    "    def call(self, input):\n",
    "        # first layer\n",
    "        #print(input.shape)\n",
    "        x_fwd = tf.nn.conv1d(input, self.kernels[0], stride = self.stride, padding = 'SAME')\n",
    "        #print(x_fwd.shape)\n",
    "        x_fwd = tf.add(x_fwd, self.biases[0])\n",
    "        x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "        x_rev = tf.nn.conv1d(input, tf.reverse(self.kernels[0], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "        x_rev = tf.add(x_fwd, self.biases[0])\n",
    "        x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "    \n",
    "        # subsequent layers\n",
    "        for layer in range(1, self.layers):\n",
    "            print(x_fwd.shape, self.kernels[layer].shape)\n",
    "            x_fwd = tf.nn.conv1d(x_fwd, self.kernels[layer], stride = self.stride, padding = 'SAME')\n",
    "            x_fwd = tf.add(x_fwd, self.biases[layer])\n",
    "            x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "            x_rev = tf.nn.conv1d(x_rev, tf.reverse(self.kernels[layer], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "            x_rev = tf.add(x_fwd, self.biases[layer])\n",
    "            x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "        \n",
    "        return tf.math.add(x_fwd, x_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([13, 4, 128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_biconv1D.kernels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([170, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "x = train_sequences_leaf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_biconv1D = BiConv1D(filters = 128, kernel_size = 13, layers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 15:39:46.287429: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:529 : Invalid argument: input must be 4-dimensional[1,170,4]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "input must be 4-dimensional[1,170,4] [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2735821/4244382421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_biconv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2735821/1008952243.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx_fwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx_fwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx_fwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d_v2\u001b[0;34m(input, filters, stride, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1974\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m       dilations=dilations)\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1891\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1894\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m       result = squeeze_batch_dims(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_benchmarks/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input must be 4-dimensional[1,170,4] [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "test_biconv1D(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to build the bidirectional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def build_bidirectional_model(motif_kernel: np.ndarray):\n",
    "    # motif_kernel.shape[2] is filters, shape[0] is kernel size\n",
    "    inputs = kl.Input((170, 4))\n",
    "    x = BiConv1D(filters = motif_kernel.shape[2], kernel_size = motif_kernel.shape[0], layers = 2)(inputs)\n",
    "    print(x.shape)\n",
    "    x = kl.Conv1D(filters = 128, kernel_size = 13, padding = 'same', activation = 'relu')(x)\n",
    "    x = kl.Dropout(0.15)(x)\n",
    "    x = kl.Flatten()(x)\n",
    "    x = kl.Dense(64)(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Activation('relu')(x)\n",
    "    outputs = kl.Dense(1)(x)\n",
    "    model = k.Model(inputs = inputs, outputs = outputs, name = \"BiDirectionalCNN\")\n",
    "    # initialize first layer kernel with motifs\n",
    "    model.layers[1].kernels[0].assign(motif_kernel)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "kernel = k.initializers.glorot_uniform()(shape = (13, 4, 128)).numpy()\n",
    "\n",
    "# overwrite part of kernel with pfms from motifs\n",
    "for i, motif_id in enumerate(all_motifs):\n",
    "    motif = all_motifs[motif_id]\n",
    "    \n",
    "    # convert PFM to PWM, assume equal background frequency of 0.25\n",
    "    # truncates motifs longer than 13bp to 13bp\n",
    "    kernel[:min(len(motif), kernel.shape[0]), :, i] = motif.pfm[:min(len(motif), kernel.shape[0]), :] / 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and compile the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 4, 128) (13, 4, 128)\n",
      "(None, 170, 128) (13, 4, 128)\n",
      "(None, 170, 128)\n",
      "(13, 4, 128) (13, 4, 128)\n",
      "(None, 170, 128) (13, 4, 128)\n",
      "(None, 170, 128)\n"
     ]
    }
   ],
   "source": [
    "model_leaf = build_bidirectional_model(kernel)\n",
    "model_proto = build_bidirectional_model(kernel)\n",
    "\n",
    "model_leaf.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "model_proto.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['mean_squared_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(13, 4, 128) dtype=float32, numpy=\n",
       "array([[[ 5.09999990e-01,  5.23999989e-01,  2.18181992e+00, ...,\n",
       "         -3.42295580e-02, -2.85419505e-02, -1.69609897e-02],\n",
       "        [ 1.50600004e+00,  1.86800003e+00,  1.27272797e+00, ...,\n",
       "          2.15757377e-02, -5.14964163e-02, -1.93520263e-03],\n",
       "        [ 4.77999985e-01,  5.60000002e-01,  3.63635987e-01, ...,\n",
       "         -9.69294459e-03,  3.43855210e-02, -3.82074304e-02],\n",
       "        [ 1.50600004e+00,  1.04799998e+00,  1.81820005e-01, ...,\n",
       "          2.78968103e-02,  5.60831390e-02, -4.69607711e-02]],\n",
       "\n",
       "       [[ 6.29999995e-01,  6.71999991e-01,  5.45455992e-01, ...,\n",
       "         -4.68777642e-02,  3.23389880e-02, -2.79120244e-02],\n",
       "        [ 1.59399998e+00,  1.38399994e+00,  1.45454395e+00, ...,\n",
       "          5.82009517e-02, -3.37831452e-02, -4.82186303e-03],\n",
       "        [ 7.96000004e-01,  3.72000009e-01,  2.00000000e+00, ...,\n",
       "          5.82192950e-02,  1.47493184e-03,  1.61478184e-02],\n",
       "        [ 9.81999993e-01,  1.57200003e+00,  0.00000000e+00, ...,\n",
       "          1.60683058e-02,  5.04928939e-02,  3.80295850e-02]],\n",
       "\n",
       "       [[ 9.95999992e-01,  1.63999999e+00,  1.81820005e-01, ...,\n",
       "          5.90779446e-02, -5.77239506e-02,  2.67917998e-02],\n",
       "        [ 1.21200001e+00,  9.20000017e-01,  2.54545593e+00, ...,\n",
       "          4.99733426e-02,  3.75769101e-02, -1.12528726e-02],\n",
       "        [ 7.87999988e-01,  3.00000012e-01,  1.27272797e+00, ...,\n",
       "          4.60451506e-02,  3.01878341e-02,  1.56866759e-03],\n",
       "        [ 1.00399995e+00,  1.13999999e+00,  0.00000000e+00, ...,\n",
       "         -1.73722990e-02,  4.54606079e-02,  2.77520157e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.36399996e+00, -3.70578803e-02, -3.53249311e-02, ...,\n",
       "          3.62383202e-03,  4.75322790e-02,  5.03661297e-02],\n",
       "        [ 1.12000003e-01,  1.82571448e-02,  5.62660210e-02, ...,\n",
       "          4.52622585e-02, -6.13527372e-03,  1.41778402e-02],\n",
       "        [ 1.43999994e-01, -4.24161926e-03, -1.70624666e-02, ...,\n",
       "         -4.50640433e-02, -1.40804052e-02,  9.77213308e-03],\n",
       "        [ 2.38199997e+00, -3.34532373e-02,  4.50811274e-02, ...,\n",
       "         -4.27537039e-03, -4.89777997e-02, -2.79532894e-02]],\n",
       "\n",
       "       [[ 2.78200006e+00,  1.15412138e-02, -1.94288716e-02, ...,\n",
       "          3.43644880e-02,  1.69336833e-02,  7.01868162e-03],\n",
       "        [ 3.26000005e-01,  4.11574505e-02, -5.68249784e-02, ...,\n",
       "         -1.17017664e-02, -6.33350760e-03, -4.69160676e-02],\n",
       "        [ 4.77999985e-01,  1.28103010e-02, -1.31594390e-02, ...,\n",
       "          3.22198011e-02,  3.01546864e-02, -2.69790329e-02],\n",
       "        [ 4.14000005e-01,  1.22205727e-02,  3.14826779e-02, ...,\n",
       "         -1.69690326e-03,  1.12017505e-02,  2.26848833e-02]],\n",
       "\n",
       "       [[ 5.01999974e-01, -1.29335634e-02, -2.61741951e-02, ...,\n",
       "         -5.62401116e-03,  3.98520045e-02,  8.75877216e-03],\n",
       "        [ 1.72800004e+00, -1.91187114e-03, -1.86912939e-02, ...,\n",
       "         -5.03837205e-02, -2.49423385e-02,  1.91969909e-02],\n",
       "        [ 1.26600003e+00, -5.51792197e-02,  2.57739089e-02, ...,\n",
       "         -9.82213765e-03, -4.83237207e-04,  6.53454289e-03],\n",
       "        [ 5.01999974e-01, -4.69361134e-02, -5.52097708e-02, ...,\n",
       "         -3.53347808e-02,  3.19526754e-02,  1.05041005e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_leaf.layers[1].kernels[0].assign(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model_leaf.layers[1].kernels[0].assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiDirectionalCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 170, 4)]          0         \n",
      "_________________________________________________________________\n",
      "bi_conv1d_22 (BiConv1D)      (None, 170, 128)          13568     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 170, 128)          213120    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 170, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 21760)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                1392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,619,713\n",
      "Trainable params: 1,619,585\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_leaf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 170, 128) (13, 4, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-2.5242045 ],\n",
       "       [-1.2794774 ],\n",
       "       [-3.0523503 ],\n",
       "       [-4.022568  ],\n",
       "       [-2.6675708 ],\n",
       "       [-1.9576894 ],\n",
       "       [-3.6684172 ],\n",
       "       [-3.4411936 ],\n",
       "       [-0.42636138],\n",
       "       [-1.6052363 ]], dtype=float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_leaf(train_sequences_leaf[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "earlyStop = k.callbacks.EarlyStopping(patience = 5)\n",
    "reduceLR = k.callbacks.ReduceLROnPlateau(patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for the tobacco leaf system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('model_leaf'):\n",
    "    # load previously trained model\n",
    "    model_leaf = k.models.load_model('model_leaf')\n",
    "else:\n",
    "    # train model\n",
    "    model_leaf.fit(\n",
    "        train_sequences_leaf,\n",
    "        train_enrichment_leaf, \n",
    "        epochs = 25,\n",
    "        batch_size = 128,\n",
    "        validation_split = 0.1,\n",
    "        callbacks = [earlyStop, reduceLR],\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model_leaf.save('model_leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for the maize protoplast system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('model_proto'):\n",
    "    # load previously trained model\n",
    "    model_proto = k.models.load_model('model_proto')\n",
    "else:\n",
    "    # train model\n",
    "    model_proto.fit(\n",
    "        train_sequences_proto,\n",
    "        train_enrichment_proto, \n",
    "        epochs = 25,\n",
    "        batch_size = 128,\n",
    "        validation_split = 0.1,\n",
    "        callbacks = [earlyStop, reduceLR],\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model_proto.save('model_proto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict enrichment for the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC1F7CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC1F7CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC206C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC206C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_enrichment_train_leaf = model_leaf.predict(np.stack(train_sequences_leaf))\n",
    "predicted_enrichment_test_leaf = model_leaf.predict(np.stack(test_sequences_leaf))\n",
    "predicted_enrichment_train_proto = model_proto.predict(np.stack(train_sequences_proto))\n",
    "predicted_enrichment_test_proto = model_proto.predict(np.stack(test_sequences_proto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predicted values to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_test_leaf['prediction'] = predicted_enrichment_test_leaf\n",
    "data_train_leaf['prediction'] = predicted_enrichment_train_leaf\n",
    "data_test_proto['prediction'] = predicted_enrichment_test_proto\n",
    "data_train_proto['prediction'] = predicted_enrichment_train_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename column with species identifier (for compatibility with LaTeX plotting code) and shuffle data to avoid one species always being drawn on top of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_test_leaf = data_test_leaf.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_train_leaf = data_train_leaf.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_test_proto = data_test_proto.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_train_proto = data_train_proto.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the correlation between the measured and predicted enrichment (overall and for each species individually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_cor(data):\n",
    "    samples = ['all', 'At', 'Zm', 'Sb']\n",
    "\n",
    "    rsquare = []\n",
    "    spearman = []\n",
    "\n",
    "    for species in samples:\n",
    "        if species == 'all':\n",
    "            data_filt = data\n",
    "        else:\n",
    "            data_filt = data[data['sample.name'] == species]\n",
    "        \n",
    "        rsquare.append(round(data_filt['enrichment'].corr(data_filt['prediction'])**2, 2))\n",
    "        spearman.append(round(data_filt['enrichment'].corr(data_filt['prediction'], method = 'spearman'), 2))\n",
    "\n",
    "    return pd.DataFrame({'sample.name' : samples, 'spearman' : spearman, 'rsquare' : rsquare})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation for test and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "correlation_test_leaf = get_cor(data_test_leaf)\n",
    "correlation_train_leaf = get_cor(data_train_leaf)\n",
    "correlation_test_proto = get_cor(data_test_proto)\n",
    "correlation_train_proto = get_cor(data_train_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well the model performed on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data in tobacco leaf system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.89     0.79\n",
      "1          At      0.81     0.69\n",
      "2          Zm      0.89     0.79\n",
      "3          Sb      0.89     0.79\n",
      "\n",
      "Test data in tobacco leaf system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.84     0.71\n",
      "1          At      0.73     0.57\n",
      "2          Zm      0.86     0.73\n",
      "3          Sb      0.85     0.71\n",
      "\n",
      "Training data in maize protoplast system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.86     0.77\n",
      "1          At      0.84     0.72\n",
      "2          Zm      0.86     0.76\n",
      "3          Sb      0.82     0.75\n",
      "\n",
      "Test data in maize protoplast system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.79     0.67\n",
      "1          At      0.74     0.58\n",
      "2          Zm      0.81     0.69\n",
      "3          Sb      0.75     0.65\n"
     ]
    }
   ],
   "source": [
    "print('Training data in tobacco leaf system:')\n",
    "print(correlation_train_leaf)\n",
    "print('\\nTest data in tobacco leaf system:')\n",
    "print(correlation_test_leaf)\n",
    "print('\\nTraining data in maize protoplast system:')\n",
    "print(correlation_train_proto)\n",
    "print('\\nTest data in maize protoplast system:')\n",
    "print(correlation_test_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_test_leaf.to_csv('../figures/rawData/CNN_test_leaf_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "data_test_proto.to_csv('../figures/rawData/CNN_test_proto_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "# data_train_leaf.to_csv('../figures/rawData/CNN_train_leaf_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "# data_train_proto.to_csv('../figures/rawData/CNN_train_proto_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "\n",
    "correlation_test_leaf.to_csv('../figures/rawData/CNN_test_leaf_stats.tsv', sep = '\\t', index = False)\n",
    "correlation_test_proto.to_csv('../figures/rawData/CNN_test_proto_stats.tsv', sep = '\\t', index = False)\n",
    "# correlation_train_leaf.to_csv('../figures/rawData/CNN_train_leaf_stats.tsv', sep = '\\t', index = False)\n",
    "# correlation_train_proto.to_csv('../figures/rawData/CNN_train_proto_stats.tsv', sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_benchmarks",
   "language": "python",
   "name": "eugene_benchmarks"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
