{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import eugene as eu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import pyranges as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SiteName2bindingSiteSequence_file =  \"../../../_data/siteName2bindingSiteSequence.pkl\"\n",
    "ets_aff_file = \"../../../_data/parsed_Ets1_8mers.txt\"\n",
    "gata_aff_file = \"../../../_data/parsed_Gata6_3769_contig8mers.txt\"\n",
    "def loadSiteName2bindingSiteSequence(file=SiteName2bindingSiteSequence_file, pickle_obj=True):\n",
    "    if pickle_obj:\n",
    "        with open(file, 'rb') as handle:\n",
    "            b = pickle.load(handle)\n",
    "        return b\n",
    "    else:\n",
    "        print(\"Only pickles at this time\")\n",
    "\n",
    "# Load Ets1 affinities into a dictionary with keys being all possible 8-mers and values being binding affinities (consensus=1)\n",
    "def loadEtsAff(file):\n",
    "    ref = file\n",
    "    Seq2EtsAff  = {line.split('\\t')[0]:float(line.split('\\t')[1]) for line in open(ref,'r').readlines()}\n",
    "    return Seq2EtsAff\n",
    "\n",
    "\n",
    "# Load Gata6 Badis 2009 affinities into a dictionary with keys being all possible 8-mers and values being binding affinities (consensus=1)\n",
    "def loadGata6Aff(file):\n",
    "    ref = file\n",
    "    Seq2GataAff = {line.split('\\t')[0]:float(line.split('\\t')[1]) for line in open(ref,'r').readlines()}\n",
    "    return Seq2GataAff\n",
    "\n",
    "def merge_dict(dict1, dict2):\n",
    "    keys = set(dict1.keys()).union(dict2.keys())\n",
    "    output = {k:max(dict1.get(k,float('-inf')), dict2.get(k, float('-inf'))) for k in keys}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motifs and names\n",
    "site_dict = loadSiteName2bindingSiteSequence()\n",
    "for k in list(site_dict.keys()):\n",
    "    if k.startswith('S'):\n",
    "        del site_dict[k]\n",
    "\n",
    "# Affinities\n",
    "ets_aff = loadEtsAff(ets_aff_file)\n",
    "gata_aff = loadGata6Aff(gata_aff_file)\n",
    "aff_dict = merge_dict(ets_aff, gata_aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def flip(map):\n",
    "    return {v: k for k, v in map.items()}\n",
    "\n",
    "def find_motifs_seq(seq, motifs, motif_names=None, starting_pos=0, rev_comp=True):\n",
    "    \"\"\"Function to find motifs and annotate the position and orientation of motifs in sequences\n",
    "    \n",
    "    Users should be able to specify an exact motif or pass in motif to search for.\n",
    "    Can make use of the JASPAR database to find motifs.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(motifs, dict):\n",
    "        motif_names = list(motifs.keys())\n",
    "        motifs = list(motifs.values())\n",
    "    if rev_comp:\n",
    "        rev_motifs = list(eu.pp.reverse_complement_seqs(motifs, verbose=False))\n",
    "        all_motifs = motifs + rev_motifs\n",
    "        orientations = [\"F\"] * len(motifs) + [\"R\"] * len(rev_motifs)\n",
    "        if motif_names is not None:\n",
    "            all_motif_names = motif_names + motif_names\n",
    "        else:\n",
    "            all_motif_names = [f\"motif{i}\" for i in range(len(motifs))] + [f\"motif{i}\" for i in range(len(motifs))]\n",
    "    else:\n",
    "        all_motifs = motifs\n",
    "        orientations = [\"F\"] * len(motifs)\n",
    "        if motif_names is not None:\n",
    "            all_motif_names = motif_names\n",
    "        else:\n",
    "            all_motif_names = [f\"motif{i}\" for i in range(len(motifs))]\n",
    "    longest_motif = max(motifs, key=len)\n",
    "    shortest_motif = min(motifs, key=len)\n",
    "    motif_name_dict = dict(zip(all_motifs, all_motif_names))\n",
    "    motif_orient_dict = dict(zip(all_motifs, orientations))\n",
    "    motif_hits_dict = {}\n",
    "    for i in range(starting_pos, len(seq)-len(shortest_motif)+1):\n",
    "        for j in range(len(longest_motif), len(shortest_motif)-1, -1):\n",
    "            motif = seq[i:i+j]\n",
    "            if motif in all_motifs:\n",
    "                #print(motif_name_dict[motif], motif_orient_dict[motif], i)\n",
    "                motif_hits_dict.setdefault(i, []).append(motif_name_dict[motif])\n",
    "                motif_hits_dict.setdefault(i, []).append(motif_orient_dict[motif])\n",
    "    return motif_hits_dict\n",
    "\n",
    "def find_affinities_seq(motif_hits, seq, affinity_dict, left_ext=0, right_ext=0):\n",
    "    \"\"\"Function to find affinities of sequence motif hits. Must have run find_motifs first.\n",
    "\n",
    "    Will probably need to have users supply motif-affinity mapping or rely on some database. I can ask about this\n",
    "    \"\"\"\n",
    "    if isinstance(left_ext, int):\n",
    "        left_ext = [left_ext] * len(motif_hits)\n",
    "    if isinstance(right_ext, int):\n",
    "        right_ext = [right_ext] * len(motif_hits)\n",
    "    for i, pos in enumerate(motif_hits.keys()):\n",
    "        start = pos - left_ext[i]\n",
    "        end = pos + right_ext[i]\n",
    "        if start < 0:\n",
    "            offset = abs(start)\n",
    "            start = 0\n",
    "            end += offset\n",
    "        if end > len(seq):\n",
    "            offset = end - len(seq)\n",
    "            end = len(seq)\n",
    "            start -= offset\n",
    "        seqlet = seq[start:end]\n",
    "        motif_hits[pos].append(seqlet)\n",
    "        motif_hits[pos].append(affinity_dict[seqlet])\n",
    "    return motif_hits \n",
    "\n",
    "def find_spacings_seq(motif_hits, left_ext=0, right_ext=0):\n",
    "    \"\"\"Function to find spacings between motifs. Must have run find_motifs first.\n",
    "    \n",
    "    Pretty straightforward. Just need to find the distance between motifs. But this will be a bit tricky\n",
    "    for overlapping motifs and we need to provide multiple ways to handle this.\n",
    "    \"\"\"\n",
    "    if isinstance(left_ext, int):\n",
    "        left_ext = [left_ext] * len(motif_hits)\n",
    "    if isinstance(right_ext, int):\n",
    "        right_ext = [right_ext] * len(motif_hits)\n",
    "    sorted_hits = sorted(motif_hits.keys())\n",
    "    previous_pos = 0\n",
    "    for i, pos in enumerate(sorted_hits):\n",
    "        if i == 0:\n",
    "            spacing = (pos-left_ext[i])-(previous_pos) \n",
    "        else:\n",
    "            spacing = (pos-left_ext[i])-(previous_pos)-1 \n",
    "        if spacing < 0:\n",
    "            spacing = 0\n",
    "        motif_hits[pos].append(spacing)\n",
    "        previous_pos = pos+right_ext[i]-1\n",
    "    return motif_hits\n",
    "\n",
    "def define_seq(seq, motifs, motif_names=None, affinity_dict=None, left_ext=0, right_ext=0, starting_pos=0, rev_comp=True):\n",
    "    \"\"\"Functon to define sequences based on motif hits and spacings.\n",
    "\n",
    "    This wiil most likely return a dictionary in uns or something. This will stop short of full on encodings but is \n",
    "    kind of the precursor step to those encodings.\n",
    "    \n",
    "    \"\"\"\n",
    "    motif_hits = find_motifs_seq(seq, motifs, motif_names, starting_pos, rev_comp)\n",
    "    if affinity_dict is not None:\n",
    "        motif_hits = find_affinities_seq(motif_hits, seq, affinity_dict, left_ext, right_ext)\n",
    "    motif_hits = find_spacings_seq(motif_hits, left_ext, right_ext)\n",
    "    return motif_hits\n",
    "\n",
    "def annotate_with_motifs_sdata(sdata, motifs, motif_names=None, affinity_dict=None, left_ext=0, right_ext=0, starting_pos=0, rev_comp=True, copy=False):\n",
    "    \"\"\"Convert a list of names and sequences to a dictionary of pyRanges objects\"\"\"\n",
    "    sdata = sdata.copy() if copy else sdata\n",
    "    d = {\"Chromosome\": [], \"Start\": [], \"End\": [], \"Strand\": [], \"Name\": [], \"Affinity\": [], \"Spacing\": []}\n",
    "    seqs = sdata.seqs\n",
    "    names = sdata.names\n",
    "    for i, seq in tqdm(enumerate(seqs)):\n",
    "        feature_def = define_seq(seq, motifs, motif_names, affinity_dict, left_ext, right_ext, starting_pos, rev_comp)\n",
    "        name = names[i]\n",
    "        for key in feature_def.keys():\n",
    "            if key - left_ext < 0:\n",
    "                start = 0\n",
    "                offset = abs(key - left_ext)\n",
    "            else:\n",
    "                start = key - left_ext\n",
    "            if (int(key-left_ext) + len(feature_def[key][2])-1) > len(seq):\n",
    "                end = len(seq)\n",
    "            else:\n",
    "                end = int(key-left_ext) + len(feature_def[key][2])-1\n",
    "            d[\"Chromosome\"].append(name)\n",
    "            d[\"Start\"].append(int(start))\n",
    "            d[\"End\"].append(end)\n",
    "            d[\"Strand\"].append(\"+\" if feature_def[key][1] == \"F\" else \"-\")\n",
    "            d[\"Name\"].append(feature_def[key][0])\n",
    "            d[\"Affinity\"].append(feature_def[key][3])\n",
    "            d[\"Spacing\"].append(feature_def[key][4])\n",
    "    sdata.pos_annot = pr.from_dict(d)\n",
    "    return sdata if copy else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdataframe = eu.dl.read_csv(\"../../../_data/ols_mini.tsv\", seq_col=\"SEQ\", sep=\"\\t\", return_dataframe=True)\n",
    "sdata = eu.dl.SeqData(seqs=sdataframe[\"SEQ\"], seqs_annot=sdataframe[sdataframe.columns.drop(\"SEQ\")])\n",
    "sdata.names = sdataframe[\"NAME\"]\n",
    "seq = sdata.seqs[12]\n",
    "name = sdata.names[12]\n",
    "motifs = [\"GGAA\", \"GGAT\", \"GATA\"]\n",
    "motif_names = [\"ETS\", \"ETS\", \"GATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['GATA', 'F', 'AGATATTC', 0.22349790163100094, 0],\n",
       " 21: ['GATA', 'F', 'AAGATAGG', 0.44555488676087596, 12],\n",
       " 36: ['GATA', 'R', 'GTTATCTC', 0.8467717279226579, 7],\n",
       " 49: ['ETS', 'F', 'ACGGAAGT', 0.5819540373459362, 5],\n",
       " 59: ['ETS', 'F', 'AAGGAAAT', 0.39163576347437207, 2]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single seq functions\n",
    "#motif_hits = find_motifs_seq(seq, motifs, motif_names=motif_names, starting_pos=2)\n",
    "#motif_hits = find_affinities(motif_hits, seq, aff_dict, left_ext=2, right_ext=6)\n",
    "#motif_hits = find_spacings(motif_hits, left_ext=2, right_ext=5)\n",
    "motif_hits = define_seq(seq, motifs, motif_names=motif_names, affinity_dict=aff_dict, left_ext=2, right_ext=6, starting_pos=0)\n",
    "motif_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6a9d8c48a45438d6118f8a750170e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotate_with_motifs_sdata(sdata, motifs=motifs, motif_names=motif_names, affinity_dict=aff_dict, left_ext=2, right_ext=6, starting_pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Name</th>\n",
       "      <th>Affinity</th>\n",
       "      <th>Spacing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>+</td>\n",
       "      <td>ETS</td>\n",
       "      <td>0.581954</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>+</td>\n",
       "      <td>ETS</td>\n",
       "      <td>0.391636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>+</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>-</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.268038</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>-</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>+</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>+</td>\n",
       "      <td>ETS</td>\n",
       "      <td>0.581954</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5062</th>\n",
       "      <td>S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5063</th>\n",
       "      <td>S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>GATA</td>\n",
       "      <td>0.270857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5064</th>\n",
       "      <td>S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>-</td>\n",
       "      <td>ETS</td>\n",
       "      <td>0.391636</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5065 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+---------------------------------------+-----------+-----------+-------+\n",
       "| Chromosome                            | Start     | End       | +4    |\n",
       "| (category)                            | (int32)   | (int32)   | ...   |\n",
       "|---------------------------------------+-----------+-----------+-------|\n",
       "| S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6 | 12        | 19        | ...   |\n",
       "| S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6 | 22        | 29        | ...   |\n",
       "| S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6 | 37        | 44        | ...   |\n",
       "| S1-E1F-S2-E2F-S3-G3F-S4-G2R-S5-G1R-S6 | 50        | 57        | ...   |\n",
       "| ...                                   | ...       | ...       | ...   |\n",
       "| S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6 | 37        | 44        | ...   |\n",
       "| S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6 | 0         | 7         | ...   |\n",
       "| S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6 | 13        | 20        | ...   |\n",
       "| S5-G3R-S4-G2R-S2-G1F-S3-E1F-S1-E2R-S6 | 57        | 64        | ...   |\n",
       "+---------------------------------------+-----------+-----------+-------+\n",
       "Stranded PyRanges object has 5,065 rows and 7 columns from 1000 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome and Strand.\n",
       "4 hidden columns: Strand, Name, Affinity, Spacing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.pos_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_sdata_in_place(sdata, mask):\n",
    "    \"\"\"Slice a SeqData object in place\"\"\"\n",
    "    if sdata.names is not None:\n",
    "        sdata.names = sdata.names[~mask]\n",
    "    if sdata.seqs is not None:\n",
    "        sdata.seqs = sdata.seqs[~mask]\n",
    "        #sdata.n_obs = len(sdata.seqs)\n",
    "    if sdata.seqs_annot is not None:\n",
    "        sdata.seqs_annot = sdata.seqs_annot[~mask]\n",
    "    if sdata.ohe_seqs is not None:\n",
    "        sdata.ohe_seqs = sdata.ohe_seqs[~mask]\n",
    "        #sdata.n_obs = len(sdata.ohe_seqs)\n",
    "    if sdata.ohe_rev_seqs is not None:\n",
    "        sdata.ohe_rev_seqs = sdata.ohe_rev_seqs[~mask]\n",
    "    return None\n",
    "\n",
    "def convert_pos_annot_to_mtx(sdata, seqsm_key=\"raw_encoding\", copy=False):\n",
    "    \"\"\"Convert a pyRanges object to a mtx\"\"\"\n",
    "    df = sdata.pos_annot.df\n",
    "    df = df.set_index(\"Chromosome\").sort_values(by= \"Start\")\n",
    "    df = df.loc[sdata.names]\n",
    "    encodings = df.groupby(\"Chromosome\").apply(lambda x: np.concatenate(x[[\"Spacing\", \"Name\", \"Strand\", \"Affinity\"]].values)).values\n",
    "    sdata.seqsm[seqsm_key] = encodings\n",
    "\n",
    "def fix_jagged_array_sdata(sdata, seqsm_key=\"raw_encoding\", strategy=\"remove\", copy=False):\n",
    "    \"\"\"Fix jagged array by padding with 0s\"\"\"\n",
    "    arr = sdata.seqsm[seqsm_key]\n",
    "    if strategy == \"remove\":\n",
    "        mismatched_dims = np.array([len(row) != len(arr[0]) for row in arr])\n",
    "        arr = arr[~mismatched_dims]\n",
    "        sdata = sdata[~mismatched_dims]\n",
    "        sdata.seqsm[f\"{seqsm_key}_cleaned\"] = np.stack(arr)\n",
    "        return sdata\n",
    "    elif strategy == \"hack\":\n",
    "        min_len = min([len(x) for x in arr])\n",
    "        arr = [x[:min_len] for x in arr]\n",
    "    elif strategy == \"pad\":\n",
    "        max_len = max([len(x) for x in arr])\n",
    "        arr = [np.pad(x, (0, max_len-len(x)), \"constant\") for x in arr]\n",
    "    sdata = sdata.copy() if copy else sdata\n",
    "    sdata.seqsm[f\"{seqsm_key}_cleaned\"] = np.stack(arr)\n",
    "    return sdata if copy else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pos_annot_to_mtx(sdata, seqsm_key=\"raw_encoding\")\n",
    "sdata = fix_jagged_array_sdata(sdata, seqsm_key=\"raw_encoding\", strategy=\"remove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 'ETS', '+', 0.5819540373459362, 2, 'ETS', '+',\n",
       "       0.39163576347437207, 7, 'GATA', '+', 0.44555488676087596, 5,\n",
       "       'GATA', '-', 0.26803787076916263, 0, 'GATA', '-',\n",
       "       0.8467717279226579], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.seqsm[\"raw_encoding_cleaned\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqData object with = 935 seqs\n",
       "seqs = (935,)\n",
       "names = (935,)\n",
       "rev_seqs = None\n",
       "ohe_seqs = None\n",
       "ohe_rev_seqs = None\n",
       "seqs_annot: 'NAME', 'MPRA_FXN', 'MICROSCOPE_FXN', 'ACTIVITY_SUMRNA_NUMDNA', 'SEQ_LEN', 'linker_1', 'TFBS_1', 'linker_2', 'TFBS_2', 'linker_3', 'TFBS_3', 'linker_4', 'TFBS_4', 'linker_5', 'TFBS_5', 'linker_6'\n",
       "pos_annot: PyRanges object with 5065 features\n",
       "seqsm: 'raw_encoding', 'raw_encoding_cleaned'\n",
       "uns: None"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sdata.seqsm[\"raw_encoding_cleaned\"]\n",
    "y = sdata.seqs_annot[\"MPRA_FXN\"].fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X).replace({\"ETS\": 0, \"GATA\": 1})\n",
    "X = X.replace({\"+\": 0, \"-\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=13)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4347/1886739963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprob_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_tr_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_tr_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_tr_probs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mprob_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_probs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mprob_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "prob_thresh = 0.5\n",
    "y_tr_probs = clf.predict_proba(X_train)[:, 1]\n",
    "y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "y_tr_preds = (y_tr_probs >= prob_thresh).astype(int)\n",
    "y_preds = (y_probs >= prob_thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a dictionary with the position of the first nucleotide of every GATA and ETS core fond in an input sequence. Also includes orientation\n",
    "def findEtsAndGataCores(seq, cores={\"ETS_FORWARD\": [\"GGAA\", \"GGAT\"], \"ETS_REVERSE\": [\"TTCC\", \"ATCC\"], \"GATA_FORWARD\": [\"GATA\"], \"GATA_REVERSE\": [\"TATC\"]}):\n",
    "    core_pos = {}\n",
    "    for i in range(2, len(seq)-5):\n",
    "        if seq[i:i+4] in cores[\"ETS_FORWARD\"]:\n",
    "            core_pos.setdefault(i, []).append(\"ETS\")\n",
    "            core_pos[i].append(\"F\")\n",
    "\n",
    "        elif seq[i:i+4] in cores[\"ETS_REVERSE\"]:\n",
    "            core_pos.setdefault(i, []).append(\"ETS\")\n",
    "            core_pos[i].append(\"R\")\n",
    "\n",
    "        elif seq[i:i+4] in cores[\"GATA_FORWARD\"]:\n",
    "            core_pos.setdefault(i, []).append(\"GATA\")\n",
    "            core_pos[i].append(\"F\")\n",
    "\n",
    "        elif seq[i:i+4] in cores[\"GATA_REVERSE\"]:\n",
    "            core_pos.setdefault(i, []).append(\"GATA\")\n",
    "            core_pos[i].append(\"R\")\n",
    "    return core_pos\n",
    "\n",
    "# Function to add the affinity and sequence of the binding site cores identified by findEtsAndGataCores()\n",
    "def findTFBSAffinity(seq, cores, ets_aff_file=\"../datasets/parsed_Ets1_8mers.txt\", gata_aff_file=\"../datasets/parsed_Gata6_3769_contig8mers.txt\"):\n",
    "    #ets_aff = loadEtsAff(ets_aff_file)\n",
    "    #gata_aff = loadGata6Aff(gata_aff_file)\n",
    "    for pos in cores.keys():\n",
    "        cores[pos].append(seq[pos-2:pos+6])\n",
    "        if cores[pos][0] == \"ETS\":\n",
    "            cores[pos].append(ets_aff[seq[pos-2:pos+6]])\n",
    "        elif cores[pos][0] == \"GATA\":\n",
    "            cores[pos].append(gata_aff[seq[pos-2:pos+6]])\n",
    "    return cores\n",
    "\n",
    "# Function to add the spacing between binding sites given a core dictionary. Specifically adds the distance from the start of each binding site to the last binding site\n",
    "def findSpacingBetweenTFBS(cores):\n",
    "    sorted_core_pos = sorted(list(cores.keys()))\n",
    "    previous_pos = 0\n",
    "    for i, pos in enumerate(sorted_core_pos):\n",
    "        if i == 0:\n",
    "            cores[pos].append((pos-2)-(previous_pos))\n",
    "        else:\n",
    "            cores[pos].append((pos-2)-(previous_pos)-1)\n",
    "        previous_pos = pos+5\n",
    "    return cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_motifs_seqs(seqs, motifs, motif_names=None, starting_pos=0, rev_comp=True):\n",
    "    \"\"\"Function to find motifs and annotate the position and orientation of motifs in sequences\n",
    "    \n",
    "    Users should be able to specify an exact motif or pass in motif to search for.\n",
    "    Can make use of the JASPAR database to find motifs.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    for seq in seqs:\n",
    "        find_motifs_seq(seq, motifs, motif_names, starting_pos, rev_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21: ['GATA', 'F', 'AAGATAGG', 0.44555488676087596, 19],\n",
       " 36: ['GATA', 'R', 'GTTATCTC', 0.8467717279226579, 7],\n",
       " 49: ['ETS', 'F', 'ACGGAAGT', 0.5819540373459362, 5],\n",
       " 59: ['ETS', 'F', 'AAGGAAAT', 0.39163576347437207, 2]}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = findEtsAndGataCores(seq)\n",
    "cores = findTFBSAffinity(seq, cores)\n",
    "findSpacingBetweenTFBS(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(encoding_type = \"\"):\n",
    "    \"\"\"Function to encode a single sequence based on a specified encoding type.\n",
    "\n",
    "    Ideas for encoding types:\n",
    "    - kmer frequencies\n",
    "    - motif \"mixed\" encodings\n",
    "    - based on columns of seqs\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def encode_seqs():\n",
    "    pass\n",
    "\n",
    "def encode_seqs_sdata():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
