{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661f6b58",
   "metadata": {},
   "source": [
    "# Testing `ResidualBind` model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64213c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *11/05/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook for testing out the custom `ResidualBind` model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLiftShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpnetlite\n",
    "import time \n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from .losses import MNLLLoss\n",
    "from .losses import log1pMSELoss\n",
    "\n",
    "from .performance import pearson_corr\n",
    "from .performance import calculate_performance_measures\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "class BPNet(torch.nn.Module):\n",
    "\t\"\"\"A basic BPNet model with stranded profile and total count prediction.\n",
    "\tThis is a reference implementation for BPNet. The model takes in\n",
    "\tone-hot encoded sequence, runs it through: \n",
    "\t(1) a single wide convolution operation \n",
    "\tTHEN \n",
    "\t(2) a user-defined number of dilated residual convolutions\n",
    "\tTHEN\n",
    "\t(3a) profile predictions done using a very wide convolution layer \n",
    "\tthat also takes in stranded control tracks \n",
    "\tAND\n",
    "\t(3b) total count prediction done using an average pooling on the output\n",
    "\tfrom 2 followed by concatenation with the log1p of the sum of the\n",
    "\tstranded control tracks and then run through a dense layer.\n",
    "\tThis implementation differs from the original BPNet implementation in\n",
    "\ttwo ways:\n",
    "\t(1) The model concatenates stranded control tracks for profile\n",
    "\tprediction as opposed to adding the two strands together and also then\n",
    "\tsmoothing that track \n",
    "\t(2) The control input for the count prediction task is the log1p of\n",
    "\tthe strand-wise sum of the control tracks, as opposed to the raw\n",
    "\tcounts themselves.\n",
    "\t(3) A single log softmax is applied across both strands such that\n",
    "\tthe logsumexp of both strands together is 0. Put another way, the\n",
    "\ttwo strands are concatenated together, a log softmax is applied,\n",
    "\tand the MNLL loss is calculated on the concatenation. \n",
    "\t(4) The count prediction task is predicting the total counts across\n",
    "\tboth strands. The counts are then distributed across strands according\n",
    "\tto the single log softmax from 3.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tn_filters: int, optional\n",
    "\t\tThe number of filters to use per convolution. Default is 64.\n",
    "\tn_layers: int, optional\n",
    "\t\tThe number of dilated residual layers to include in the model.\n",
    "\t\tDefault is 8.\n",
    "\tn_outputs: int, optional\n",
    "\t\tThe number of profile outputs from the model. Generally either 1 or 2 \n",
    "\t\tdepending on if the data is unstranded or stranded. Default is 2.\n",
    "\talpha: float, optional\n",
    "\t\tThe weight to put on the count loss.\n",
    "\tname: str or None, optional\n",
    "\t\tThe name to save the model to during training.\n",
    "\ttrimming: int or None, optional\n",
    "\t\tThe amount to trim from both sides of the input window to get the\n",
    "\t\toutput window. This value is removed from both sides, so the total\n",
    "\t\tnumber of positions removed is 2*trimming.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, n_filters=64, n_layers=8, n_outputs=2, \n",
    "\t\tn_control_tracks=2, alpha=1, profile_output_bias=True, \n",
    "\t\tcount_output_bias=True, name=None, trimming=None):\n",
    "\t\tsuper(BPNet, self).__init__()\n",
    "\t\tself.n_filters = n_filters\n",
    "\t\tself.n_layers = n_layers\n",
    "\t\tself.n_outputs = n_outputs\n",
    "\t\tself.n_control_tracks = n_control_tracks\n",
    "\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.name = name or \"bpnet.{}.{}\".format(n_filters, n_layers)\n",
    "\t\tself.trimming = trimming or 2 ** n_layers\n",
    "\n",
    "\t\tself.iconv = torch.nn.Conv1d(4, n_filters, kernel_size=21, padding=10)\n",
    "\n",
    "\t\tself.rconvs = torch.nn.ModuleList([\n",
    "\t\t\ttorch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=2**i, \n",
    "\t\t\t\tdilation=2**i) for i in range(1, self.n_layers+1)\n",
    "\t\t])\n",
    "\n",
    "\t\tself.fconv = torch.nn.Conv1d(n_filters+n_control_tracks, n_outputs, kernel_size=75, \n",
    "\t\t\tpadding=37, bias=profile_output_bias)\n",
    "\t\t\n",
    "\t\tn_count_control = 1 if n_control_tracks > 0 else 0\n",
    "\t\tself.linear = torch.nn.Linear(n_filters+n_count_control, 1, \n",
    "\t\t\tbias=count_output_bias)\n",
    "\n",
    "\tdef forward(self, X, X_ctl=None):\n",
    "\t\t\"\"\"A forward pass of the model.\n",
    "\t\tThis method takes in a nucleotide sequence X, a corresponding\n",
    "\t\tper-position value from a control track, and a per-locus value\n",
    "\t\tfrom the control track and makes predictions for the profile \n",
    "\t\tand for the counts. This per-locus value is usually the\n",
    "\t\tlog(sum(X_ctl_profile)+1) when the control is an experimental\n",
    "\t\tread track but can also be the output from another model.\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tX: torch.tensor, shape=(batch_size, 4, sequence_length)\n",
    "\t\t\tThe one-hot encoded batch of sequences.\n",
    "\t\tX_ctl: torch.tensor, shape=(batch_size, n_strands, sequence_length)\n",
    "\t\t\tA value representing the signal of the control at each position in the\n",
    "\t\t\tsequence.\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\ty_profile: torch.tensor, shape=(batch_size, n_strands, out_length)\n",
    "\t\t\tThe output predictions for each strand.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tstart, end = self.trimming, X.shape[2] - self.trimming\n",
    "\n",
    "\t\tX = torch.nn.ReLU()(self.iconv(X))\n",
    "\t\tfor i in range(self.n_layers):\n",
    "\t\t\tX_conv = torch.nn.ReLU()(self.rconvs[i](X))\n",
    "\t\t\tX = torch.add(X, X_conv)\n",
    "\n",
    "\t\tif X_ctl is None:\n",
    "\t\t\tX_w_ctl = X\n",
    "\t\telse:\n",
    "\t\t\tX_w_ctl = torch.cat([X, X_ctl], dim=1)\n",
    "\n",
    "\t\ty_profile = self.fconv(X_w_ctl)[:, :, start:end]\n",
    "\n",
    "\t\t# counts prediction\n",
    "\t\tX = torch.mean(X[:, :, start-37:end+37], axis=2)\n",
    "\n",
    "\t\tif X_ctl is not None:\n",
    "\t\t\tX_ctl = torch.sum(X_ctl[:, :, start-37:end+37], axis=(1, 2))\n",
    "\t\t\tX_ctl = X_ctl.unsqueeze(-1)\n",
    "\t\t\tX = torch.cat([X, torch.log(X_ctl+1)], dim=-1)\n",
    "\n",
    "\t\ty_counts = self.linear(X).reshape(X.shape[0], 1)\n",
    "\t\treturn y_profile, y_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yuzu\n",
    "class BPNet(torch.nn.Module):\n",
    "\tdef __init__(self, n_inputs, n_filters=64, kernel_size=21, seq_len=None, n_layers=4, random_state=0):\n",
    "\t\tsuper(BPNet, self).__init__()\n",
    "\t\ttorch.manual_seed(random_state)\n",
    "\n",
    "\t\t\n",
    "\t\tself.iconv = torch.nn.Conv1d(n_inputs, n_filters, kernel_size=21, padding=10)\n",
    "\t\tself.irelu = torch.nn.ReLU()\n",
    "\n",
    "\t\tself.dconv1 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=2, dilation=2)\n",
    "\t\tself.drelu1 = torch.nn.ReLU()\n",
    "\n",
    "\t\tself.dconv2 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=4, dilation=4)\n",
    "\t\tself.drelu2 = torch.nn.ReLU()        \n",
    "\n",
    "\t\tself.dconv3 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=8, dilation=8)\n",
    "\t\tself.drelu3 = torch.nn.ReLU()\n",
    "\n",
    "\t\t#self.dconv4 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=16, dilation=16)\n",
    "\t\t#self.drelu4 = torch.nn.ReLU()\n",
    "\n",
    "\t\t#self.dconv5 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=32, dilation=32)\n",
    "\t\t#self.drelu5 = torch.nn.ReLU()\n",
    "\n",
    "\t\t#self.dconv6 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=64, dilation=64)\n",
    "\t\t#self.drelu6 = torch.nn.ReLU()\n",
    "\n",
    "\t\t#self.dconv7 = torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=128, dilation=128)\n",
    "\t\t#self.drelu7 = torch.nn.ReLU()\n",
    "\n",
    "\t\tself.fconv = torch.nn.Conv1d(n_filters, 1, kernel_size=75, padding=37)\n",
    "\t\t#self.logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tX = self.irelu(self.iconv(X))\n",
    "\t\t\t\n",
    "\t\t\tX = self.drelu1(self.dconv1(X))\n",
    "\t\t\tX = self.drelu2(self.dconv2(X))\n",
    "\t\t\tX = self.drelu3(self.dconv3(X))\n",
    "\n",
    "\t\t\tX = self.fconv(X)\n",
    "\t\t\t#X = self.logsoftmax(self.fconv(X))\n",
    "\t\t\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Basset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5405, 0.4398],\n",
       "        [0.6291, 0.5908],\n",
       "        [0.5014, 0.6883],\n",
       "        [0.3922, 0.7281],\n",
       "        [0.5423, 0.5404],\n",
       "        [0.4932, 0.5351],\n",
       "        [0.5355, 0.4664],\n",
       "        [0.4262, 0.4420],\n",
       "        [0.4865, 0.6399],\n",
       "        [0.4958, 0.5314]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 4, 100)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b89b94102a47d3a29709cf5f5a8de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n",
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + train_val\n"
     ]
    }
   ],
   "source": [
    "sdata = eu.datasets.random1000()\n",
    "eu.pp.ohe_seqs_sdata(sdata)\n",
    "eu.pp.train_test_split_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "Missing logger folder: /workspaces/EUGENe/tests/notebooks/implement/models/eugene_logs/ssResidualBind_regression\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type                      | Params\n",
      "-------------------------------------------------------------\n",
      "0 | hp_metric      | R2Score                   | 0     \n",
      "1 | conv           | BasicConv1D               | 4.5 K \n",
      "2 | residual_block | ResidualModule            | 83.8 K\n",
      "3 | average_pool   | AvgPool1d                 | 0     \n",
      "4 | dropout        | Dropout                   | 0     \n",
      "5 | flatten        | Flatten                   | 0     \n",
      "6 | fc             | BasicFullyConnectedModule | 2.0 M \n",
      "-------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.320     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15103dc447749308845d19db0efb48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 13\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be41c66e0c334c92a7ae592ab87011c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a7e9ff522f4e0c9760a547f1ca3254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eu.train.fit(model, sdata, target_keys=\"activity_0\", epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
