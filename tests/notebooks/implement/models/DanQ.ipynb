{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661f6b58",
   "metadata": {},
   "source": [
    "# Testing `DanQ` model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64213c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *11/05/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook for testing out the custom `DanQ` model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DanQ(nn.Module):\n",
    "    \"\"\"DanQ model from Quang and Xie, 2016; \n",
    "        see <https://academic.oup.com/nar/article/44/11/e107/2468300> \n",
    "        and <https://github.com/uci-cbcl/DanQ/blob/master/DanQ_train.py>\n",
    "        and <https://github.com/FunctionLab/selene/blob/master/models/danQ.py>\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, d=320,\n",
    "                 conv1_filters=None, learn_conv1_filters=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if d != 320:\n",
    "            print(\"NB: number of convolutional filters in original DanQ model is 320; current number of convolutional filters is not set to 320\")\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.init_conv1_filters = conv1_filters\n",
    "        \n",
    "        assert (not (conv1_filters is None and not learn_conv1_filters)), \"initial conv1_filters cannot be set to None while learn_conv1_filters is set to False\"\n",
    "        \n",
    "        # Layer 1 (convolutional), constituent parts\n",
    "        if conv1_filters is not None:\n",
    "            if learn_conv1_filters: # continue modifying existing conv1_filters through learning\n",
    "                self.conv1_filters = torch.nn.Parameter( torch.Tensor(conv1_filters) )\n",
    "            else:\n",
    "                self.register_buffer(\"conv1_filters\", torch.Tensor(conv1_filters))\n",
    "        else:\n",
    "            self.conv1_filters = torch.nn.Parameter(torch.zeros(d, 4, 26))\n",
    "            torch.nn.init.kaiming_normal_(self.conv1_filters)\n",
    "        self.activation1 = nn.ReLU() # name the first-layer activation function for hook purposes\n",
    "        self.maxpool1 = nn.MaxPool1d(13)\n",
    "        \n",
    "        # Layer 2 (bi-directional LSTM), constituent parts\n",
    "        self.bdlstm2 = nn.LSTM(d, d, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Layer 3 (fully connected), constituent parts\n",
    "        self.fc3 = nn.LazyLinear(925, bias=False)\n",
    "        \n",
    "        # Output layer (fully connected), constituent parts\n",
    "        self.fc4 = nn.Linear(925, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def get_which_conv_layers_transferred(self):\n",
    "        layers = []\n",
    "        if self.init_conv1_filters is not None:\n",
    "            layers.append(1)\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        out = torch.conv1d(x, self.conv1_filters, stride=1, padding=(self.conv1_filters.shape[-1]//2))\n",
    "        out = self.activation1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        # Layer 2\n",
    "        out = torch.transpose(out, 1, 2) # make dims (batch, seq, features) to comply with bi-dir. LSTM\n",
    "        out, _ = self.bdlstm2(out) # see <https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>\n",
    "        out = self.dropout5(out)\n",
    "        out = torch.transpose(out, 1, 2) # change dims back to (batch, features, seq)\n",
    "        \n",
    "        # Layer 3\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.fc4(out) \n",
    "        y_pred = self.sigmoid(out)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From selene\n",
    "class DanQ(nn.Module):\n",
    "    def __init__(self, sequence_length, n_genomic_features):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sequence_length : int\n",
    "            Input sequence length\n",
    "        n_genomic_features : int\n",
    "            Total number of features to predict\n",
    "        \"\"\"\n",
    "        super(DanQ, self).__init__()\n",
    "        self.nnet = nn.Sequential(\n",
    "            nn.Conv1d(4, 320, kernel_size=26),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(\n",
    "                kernel_size=13, stride=13),\n",
    "            nn.Dropout(0.2))\n",
    "\n",
    "        self.bdlstm = nn.Sequential(\n",
    "            nn.LSTM(\n",
    "                320, 320, num_layers=1, batch_first=True, bidirectional=True))\n",
    "\n",
    "        self._n_channels = math.floor(\n",
    "            (sequence_length - 25) / 13)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self._n_channels * 640, 925),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(925, n_genomic_features),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward propagation of a batch.\n",
    "        \"\"\"\n",
    "        out = self.nnet(x)\n",
    "        reshape_out = out.transpose(0, 1).transpose(0, 2)\n",
    "        out, _ = self.bdlstm(reshape_out)\n",
    "        out = out.transpose(0, 1)\n",
    "        reshape_out = out.contiguous().view(\n",
    "            out.size(0), 640 * self._n_channels)\n",
    "        predict = self.classifier(reshape_out)\n",
    "        return predict\n",
    "\n",
    "def criterion():\n",
    "    return nn.BCELoss()\n",
    "\n",
    "def get_optimizer(lr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models.base import BaseModel, BasicConv1D, BasicRecurrent, BasicFullyConnectedModule\n",
    "class DanQ(BaseModel):\n",
    "    \"\"\"DanQ model from Quang and Xie, 2016;\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_len:\n",
    "        The length of the input sequence.\n",
    "    output_dim:\n",
    "        The dimension of the output.\n",
    "    strand:\n",
    "        The strand of the model.\n",
    "    task:\n",
    "        The task of the model.\n",
    "    aggr:\n",
    "        The aggregation function.\n",
    "    fc_kwargs:\n",
    "        The keyword arguments for the fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_len: int,\n",
    "        output_dim: int,\n",
    "        strand: str = \"ss\",\n",
    "        task: str = \"regression\",\n",
    "        loss_fxn: str = \"mse\",\n",
    "        aggr: str = None,\n",
    "        cnn_kwargs: dict = {},\n",
    "        rnn_kwargs: dict = {},\n",
    "        fc_kwargs: dict = {},\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            input_len, \n",
    "            output_dim, \n",
    "            strand=strand, \n",
    "            task=task, \n",
    "            aggr=aggr, \n",
    "            loss_fxn=loss_fxn, \n",
    "            **kwargs\n",
    "        ) \n",
    "        self.conv_kwargs, self.fc_kwargs = self.kwarg_handler(cnn_kwargs, rnn_kwargs, fc_kwargs)\n",
    "        self.convnet = BasicConv1D(\n",
    "            input_len=input_len, \n",
    "            **cnn_kwargs)\n",
    "        self.recurrentnet = BasicRecurrent(\n",
    "            input_dim=self.convnet.out_channels, \n",
    "            **rnn_kwargs\n",
    "        )\n",
    "        self.fcnet = BasicFullyConnectedModule(\n",
    "            input_dim=self.recurrentnet.out_dim, \n",
    "            output_dim=output_dim, \n",
    "            **fc_kwargs\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_rev_comp=None):\n",
    "        x = self.convnet(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        out, _ = self.recurrentnet(x)\n",
    "        out = self.fcnet(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "    def kwarg_handler(self, cnn_kwargs, rnn_kwargs, fc_kwargs):\n",
    "        \"\"\"Sets default kwargs for conv and fc modules if not specified\"\"\"\n",
    "        cnn_kwargs.setdefault(\"channels\", [4, 320])\n",
    "        cnn_kwargs.setdefault(\"conv_kernels\", [26])\n",
    "        cnn_kwargs.setdefault(\"conv_strides\", [1])\n",
    "        cnn_kwargs.setdefault(\"padding\", \"same\")\n",
    "        cnn_kwargs.setdefault(\"pool_kernels\", [13])\n",
    "        cnn_kwargs.setdefault(\"omit_final_pool\", False)\n",
    "        cnn_kwargs.setdefault(\"dropout_rates\", 0.2)\n",
    "        cnn_kwargs.setdefault(\"activation\", \"relu\")\n",
    "        rnn_kwargs.setdefault(\"unit_type\", \"lstm\")\n",
    "        rnn_kwargs.setdefault(\"output_dim\", 320)\n",
    "        rnn_kwargs.setdefault(\"bidirectional\", True)\n",
    "        rnn_kwargs.setdefault(\"batch_first\", True)\n",
    "        fc_kwargs.setdefault(\"hidden_dims\", [925])\n",
    "        fc_kwargs.setdefault(\"dropout_rate\", 0.5)\n",
    "        fc_kwargs.setdefault(\"batchnorm\", False)\n",
    "        return cnn_kwargs, fc_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DanQ(input_len=1000, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py:299: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0539],\n",
       "        [ 0.0016],\n",
       "        [-0.2314],\n",
       "        [-0.0362],\n",
       "        [ 0.0626],\n",
       "        [-0.0832],\n",
       "        [ 0.0138],\n",
       "        [ 0.0010],\n",
       "        [-0.0320],\n",
       "        [-0.0125]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 4, 1000)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = eu.dl.SeqData(seqs=eu.utils.random_seqs(1000, 1000))\n",
    "sdata.make_names_unique()\n",
    "sdata[\"activity\"] = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea03461a0de4d38b0c89ec3f15c8215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n",
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + train_val\n"
     ]
    }
   ],
   "source": [
    "eu.pp.ohe_seqs_sdata(sdata)\n",
    "eu.pp.train_test_split_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "Missing logger folder: /workspaces/EUGENe/tests/notebooks/implement/models/eugene_logs/ssDanQ_regression\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name         | Type                      | Params\n",
      "-----------------------------------------------------------\n",
      "0 | hp_metric    | R2Score                   | 0     \n",
      "1 | convnet      | BasicConv1D               | 33.6 K\n",
      "2 | recurrentnet | BasicRecurrent            | 1.6 M \n",
      "3 | fcnet        | BasicFullyConnectedModule | 593 K \n",
      "-----------------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.084     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949cbb09aedd48a1a9e3114e0846fb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 13\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45df04faef734e878787d4409041820c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307b70c122bf46b284b372f92e507ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eu.train.fit(model, sdata, target_keys=\"activity\", epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
