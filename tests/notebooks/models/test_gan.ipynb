{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9ca43f-c2c5-4289-a69a-2e70385defdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPUs: NVIDIA GeForce RTX 2070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.0.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from eugene.dataload._io import read_numpy, read\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Basic import\n",
    "import eugene as eu\n",
    "eu.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d3606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = read_numpy(\"chr1.npy_ohe_seqs.npy\", ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20b8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + train_val\n"
     ]
    }
   ],
   "source": [
    "eu.pp.train_test_split_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca291be",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "latent_dim = seq_len * 4\n",
    "generator = torch.nn.Sequential(\n",
    "    eu.models.base.BasicFullyConnectedModule(\n",
    "        input_dim=500,\n",
    "        output_dim=latent_dim,\n",
    "        hidden_dims=[300]\n",
    "    ),\n",
    "    torch.nn.Tanh()\n",
    ")\n",
    "discriminator = torch.nn.Sequential(\n",
    "    eu.models.base.BasicFullyConnectedModule(\n",
    "        input_dim=latent_dim,\n",
    "        output_dim=1,\n",
    "        hidden_dims=[100]\n",
    "    ),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1cdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eu.models.GAN(\n",
    "    latent_dim=latent_dim, \n",
    "    generator=generator, \n",
    "    discriminator=discriminator,\n",
    "    gen_lr=1e-3,\n",
    "    disc_lr=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6e8646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | generator     | Sequential | 210 K \n",
      "1 | discriminator | Sequential | 20.2 K\n",
      "---------------------------------------------\n",
      "230 K     Trainable params\n",
      "0         Non-trainable params\n",
      "230 K     Total params\n",
      "0.923     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fecea3e864942cea933e9172610c616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 4, 50]) cuda:0\n",
      "torch.Size([512, 4, 50]) cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05743e0e3be54837b76e73f834b2f72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m eu\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mdl_num_workers \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m      3\u001b[0m eu\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mdl_pin_memory_gpu_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m eu\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      5\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      6\u001b[0m     sdata\u001b[39m=\u001b[39;49msdata,\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\EUGENe\\eugene\\train\\_fit.py:170\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, sdata, target_keys, train_key, epochs, gpus, batch_size, num_workers, log_dir, name, version, train_dataset, val_dataset, train_dataloader, val_dataloader, seq_transforms, transform_kwargs, early_stopping_callback, early_stopping_metric, early_stopping_patience, early_stopping_verbose, seed, verbosity, return_trainer, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(LearningRateMonitor())\n\u001b[0;32m    167\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m    168\u001b[0m     max_epochs\u001b[39m=\u001b[39mepochs, logger\u001b[39m=\u001b[39mlogger, gpus\u001b[39m=\u001b[39mgpus, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    169\u001b[0m )\n\u001b[1;32m--> 170\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    171\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloader, val_dataloaders\u001b[39m=\u001b[39;49mval_dataloader\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m return_trainer:\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[0;32m    735\u001b[0m     rank_zero_deprecation(\n\u001b[0;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m     )\n\u001b[0;32m    739\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[1;32m--> 740\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    741\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    742\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 685\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    686\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[0;32m    776\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m--> 777\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    779\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m   1198\u001b[0m \u001b[39m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[1;32m-> 1199\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch()\n\u001b[0;32m   1201\u001b[0m \u001b[39m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_dispatch()\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mstart_predicting(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1279\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mstart_training(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[39m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun_stage()\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1288\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1319\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:234\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m data_fetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mget_profiled_dataloader(dataloader)\n\u001b[0;32m    233\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(data_fetcher)\n\u001b[0;32m    236\u001b[0m     \u001b[39m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[39m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[39m# TODO(@carmocca): deprecate and rename so users don't get confused\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:140\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_skip()\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_run_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    142\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[0;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:141\u001b[0m, in \u001b[0;36mTrainingEpochLoop.on_run_start\u001b[1;34m(self, data_fetcher, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mepoch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reload_dataloader_state_dict(data_fetcher)\n\u001b[1;32m--> 141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m _update_dataloader_iter(data_fetcher, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:121\u001b[0m, in \u001b[0;36m_update_dataloader_iter\u001b[1;34m(data_fetcher, batch_idx)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"Attach the dataloader.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[0;32m    120\u001b[0m     \u001b[39m# restore iteration\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     dataloader_iter \u001b[39m=\u001b[39m \u001b[39menumerate\u001b[39;49m(data_fetcher, batch_idx)\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     dataloader_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:198\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader)\n\u001b[1;32m--> 198\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_patch()\n\u001b[0;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefetching(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefetch_batches)\n\u001b[0;32m    200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:133\u001b[0m, in \u001b[0;36mAbstractDataFetcher._apply_patch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m         loader\u001b[39m.\u001b[39m_lightning_fetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m    131\u001b[0m         patch_dataloader_iterator(loader, iterator, \u001b[39mself\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m apply_to_collections(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader_iters, (Iterator, DataLoader), _apply_patch_fn)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:181\u001b[0m, in \u001b[0;36mAbstractDataFetcher.loader_iters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mThe `dataloader_iter` isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt available outside the __iter__ context.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader, CombinedLoader):\n\u001b[1;32m--> 181\u001b[0m     loader_iters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_iter\u001b[39m.\u001b[39;49mloader_iters\n\u001b[0;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     loader_iters \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader_iter]\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:537\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.loader_iters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39m\"\"\"Get the `_loader_iters` and create one if it is None.\"\"\"\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loader_iters \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loader_iters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_loader_iters(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloaders)\n\u001b[0;32m    539\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loader_iters\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:577\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.create_loader_iters\u001b[1;34m(loaders)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39m\"\"\"Create and return a collection of iterators from loaders.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \n\u001b[0;32m    570\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[39m    a collections of iterators\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39m# dataloaders are Iterable but not Sequences. Need this to specifically exclude sequences\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m \u001b[39mreturn\u001b[39;00m apply_to_collection(loaders, Iterable, \u001b[39miter\u001b[39;49m, wrong_dtype\u001b[39m=\u001b[39;49m(Sequence, Mapping))\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:96\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39m# Breaking condition\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, dtype) \u001b[39mand\u001b[39;00m (wrong_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m elem_type \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)\n\u001b[0;32m    100\u001b[0m \u001b[39m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1027\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Lab\\anaconda3\\envs\\eugene\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "eu.settings.batch_size = 512\n",
    "eu.settings.dl_num_workers = 8\n",
    "eu.settings.dl_pin_memory_gpu_training = True\n",
    "eu.train.fit(\n",
    "    model=model,\n",
    "    sdata=sdata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc78854-191e-4714-bc83-7fa3f442e26d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('eugene')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3dbbff05fc9c23df2b8cfb8dfa1c8cab53b5b79b84eaada81073f79339e0e490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
