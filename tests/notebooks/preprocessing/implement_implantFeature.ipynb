{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a88efe-ebb3-424c-8704-fb4ee189af2c",
   "metadata": {},
   "source": [
    "# Implementing implanting a feature into sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d058003-a667-4b45-9ddc-e47efe48e0e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *09/01/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to implement adding a feature to sequences.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "2022-09-01 23:55:44.798344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-01 23:55:44.798392: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/workspaces/EUGENe/eugene/external/kipoi_veff/seqplotting_deps.py:36: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  min_coords = np.vstack(data.min(0) for data in polygons_data).min(0)\n",
      "/workspaces/EUGENe/eugene/external/kipoi_veff/seqplotting_deps.py:37: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  max_coords = np.vstack(data.max(0) for data in polygons_data).max(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Basic import\n",
    "import torch\n",
    "import numpy as np\n",
    "import eugene as eu\n",
    "eu.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = eu.datasets.random1000()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe2f4b2d7a54b278018cac6e70747e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot-encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n"
     ]
    }
   ],
   "source": [
    "eu.pp.one_hot_encode_data(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from eugene.preprocessing._utils import _token2one_hot\n",
    "from eugene.preprocessing import ohe_alphabet_seqs\n",
    "from eugene._settings import settings\n",
    "def feature_implant_seq(seq, feature, position, encoding=\"str\", onehot=False):\n",
    "    \"\"\"\n",
    "    Insert a feature at a given position in a sequence.\n",
    "    \"\"\"\n",
    "    if encoding == \"str\":\n",
    "        return seq[:position] + feature + seq[position + len(feature):]\n",
    "    elif encoding == \"onehot\":\n",
    "        if onehot:\n",
    "            feature = _token2one_hot(feature.argmax(axis=1), vocab_size=4, fill_value=0)\n",
    "        return np.concatenate(\n",
    "            (seq[:position], feature, seq[position + len(feature):]), axis=0\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Encoding not recognized.\")\n",
    "\n",
    "\n",
    "def feature_implant_across_seq(seq, feature, **kwargs):\n",
    "    \"\"\"\n",
    "    Insert a feature at every position in a sequence.\n",
    "    \"\"\"\n",
    "    implanted_seqs = []\n",
    "    for pos in range(len(seq) - len(feature)):\n",
    "        implanted_seqs.append(feature_implant_seq(seq, feature, pos, **kwargs))\n",
    "    return np.array(implanted_seqs)\n",
    "\n",
    "\n",
    "def feature_implant(model, sdata, seq_id, feature, feature_name=\"feature\", encoding=\"str\", onehot=False, device=\"cpu\", store=False):\n",
    "    \"\"\"\n",
    "    Score a set of sequences with a feature inserted at every position of each sequence in sdata\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if settings.gpus > 0 else \"cpu\" if device is None else device\n",
    "    model.to(device)\n",
    "    seq_idx = np.where(sdata.seqs_annot.index == seq_id)[0][0]\n",
    "    if encoding == \"str\":\n",
    "        seq = sdata.seqs[seq_idx]\n",
    "        implanted_seqs = feature_implant_across_seq(seq, feature, encoding=encoding)\n",
    "        implanted_seqs = ohe_alphabet_seqs(implanted_seqs)\n",
    "        X = torch.from_numpy(implanted_seqs).transpose(1, 2).float()\n",
    "    elif encoding == \"onehot\":\n",
    "        seq = sdata.ohe_seqs[seq_idx]\n",
    "        implanted_seqs = feature_implant_across_seq(\n",
    "            seq, feature, encoding=encoding, onehot=onehot\n",
    "        )\n",
    "        X = torch.from_numpy(implanted_seqs).transpose(1, 2).float()\n",
    "    else:\n",
    "        raise ValueError(\"Encoding not recognized.\")\n",
    "    X = X.to(device)\n",
    "    preds = model(X).detach().numpy().squeeze()\n",
    "    if store:\n",
    "        sdata.seqsm[f\"{seq_id}_{feature_name}_slide\"] = preds\n",
    "    return preds\n",
    "\n",
    "\n",
    "def feature_implant_sdata(model, sdata, seqsm_key=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Score a set of sequences with a feature inserted at every position of each sequence in sdata\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for i, seq_id in tqdm(enumerate(sdata.seqs_annot.index), desc=\"Implanting feature\", total=len(sdata.seqs_annot)):\n",
    "        predictions.append(feature_implant(model, sdata, seq_id, **kwargs))\n",
    "    print(seqsm_key)\n",
    "    if seqsm_key is not None:\n",
    "        sdata.seqsm[seqsm_key] = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "model = eu.models.DeepBind(input_len=66, output_dim=1)\n",
    "seq = sdata.seqs[0]\n",
    "ohe_seq = eu.pp.ohe_DNA_seq(seq)\n",
    "meme = eu.utils.MinimalMEME(path=\"../../_datasets/jores21/CPEs.meme\")\n",
    "motif = meme.motifs[\"TATA\"]\n",
    "name = motif.name\n",
    "pfm = motif.pfm\n",
    "consensus = eu.pp.decode_DNA_seq(pfm)\n",
    "pos = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AGGACAGATTTTCGCGTGTTGGGCCCAACGGATCAGCCTCTATAAACCGTATCCGACAATATAAGG',\n",
       " 'AGCCCCTATAAATACCCCTTGGGCCCAACGGATCAGCCTCTATAAACCGTATCCGACAATATAAGG',\n",
       " array([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], dtype=float16),\n",
       " array([[1.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 1.    , 0.    ],\n",
       "        [0.1275, 0.3765, 0.1195, 0.3765],\n",
       "        [0.1575, 0.3985, 0.199 , 0.2455],\n",
       "        [0.249 , 0.303 , 0.197 , 0.251 ],\n",
       "        [0.1235, 0.655 , 0.0755, 0.1455],\n",
       "        [0.01  , 0.002 , 0.002 , 0.986 ],\n",
       "        [0.968 , 0.    , 0.    , 0.032 ],\n",
       "        [0.002 , 0.014 , 0.006 , 0.978 ],\n",
       "        [0.992 , 0.    , 0.002 , 0.006 ]]),\n",
       " array([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.]], dtype=float16),\n",
       " array([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], dtype=float16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function for single seq\n",
    "implanted_seq = feature_implant_seq(seq, consensus, pos, encoding=\"str\")\n",
    "implanted_ohe_seq = feature_implant_seq(ohe_seq, pfm, pos, encoding=\"onehot\")\n",
    "implanted_full_ohe_seq = feature_implant_seq(ohe_seq, pfm, pos, encoding=\"onehot\", onehot=True)\n",
    "seq, implanted_seq, ohe_seq[0:10], implanted_ohe_seq[0:10], implanted_full_ohe_seq[0:10], ohe_seq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, (50, 66, 4), (50, 66, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function to implant across a seq\n",
    "implanted_seqs = feature_implant_across_seq(seq, consensus)\n",
    "implanted_ohe_seqs = feature_implant_across_seq(ohe_seq, pfm, encoding=\"onehot\")\n",
    "implanted_full_ohe_seqs = feature_implant_across_seq(ohe_seq, pfm, encoding=\"onehot\", onehot=True)\n",
    "len(implanted_seqs), implanted_ohe_seqs.shape, implanted_full_ohe_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12860738, -0.20724249, -0.09944402, -0.15735872, -0.07232916,\n",
       "        0.10080706, -0.05799149, -0.00366257, -0.13281582, -0.03578924,\n",
       "        0.07352825, -0.08969332, -0.14790955, -0.19986603, -0.17278814,\n",
       "       -0.18217488, -0.07786699, -0.18028736, -0.13209815, -0.0564633 ,\n",
       "       -0.15503126, -0.09165487, -0.11240477, -0.0220406 , -0.00690747,\n",
       "       -0.05037049, -0.13428695, -0.07957186,  0.05299611, -0.00722817,\n",
       "       -0.05692093, -0.06351749, -0.12362285, -0.04635581, -0.10504552,\n",
       "        0.02596581,  0.10609262, -0.04033621, -0.09065762, -0.05444472,\n",
       "       -0.05513809, -0.08035021, -0.02563847, -0.05098003,  0.05189031,\n",
       "       -0.14998351,  0.04425012,  0.00295492, -0.0998994 , -0.09659025],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function for single seq in sdata\n",
    "predictions = feature_implant(\n",
    "    model=model, \n",
    "    sdata=sdata, \n",
    "    feature=pfm, \n",
    "    seq_id=sdata.names[0],\n",
    "    encoding=\"onehot\", \n",
    "    onehot=True,\n",
    "    store=True,\n",
    "    feature_name=name\n",
    ")\n",
    "sdata.seqsm[\"seq000_TATA_slide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e43a3bc6b3432c8c6d2e2221c519e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Implanting feature:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide_TATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function for whole sdata object\n",
    "feature_implant_sdata(\n",
    "    model=model, \n",
    "    sdata=sdata, \n",
    "    feature=pfm, \n",
    "    seqsm_key=f\"slide_{name}\",\n",
    "    encoding=\"onehot\", \n",
    "    onehot=True\n",
    ")\n",
    "sdata.seqsm[f\"slide_{name}\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
