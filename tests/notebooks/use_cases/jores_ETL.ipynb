{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jores et al 2021 Extract-Transform-Load\n",
    "**Authorship:**\n",
    "Adam Klie, *08/11/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to extract, transform, and load data from the Jores et al (2021) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "2022-08-12 00:14:07.583999: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-12 00:14:07.584046: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import eugene as eu\n",
    "eu.settings.dataset_dir = \"../../_data/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load in the dataset to a raw `SeqData` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset jores21 CNN_test_leaf.tsv has already been dowloaded.\n",
      "Dataset jores21 CNN_train_leaf.tsv has already been dowloaded.\n",
      "Dataset jores21 CNN_train_proto.tsv has already been dowloaded.\n",
      "Dataset jores21 CNN_test_proto.tsv has already been dowloaded.\n"
     ]
    }
   ],
   "source": [
    "# Load in the downloaded datasets from the manuscript Github repo\n",
    "sdata_leaf_raw = eu.datasets.jores21(dataset=\"leaf\")\n",
    "sdata_proto_raw = eu.datasets.jores21(dataset=\"proto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the datasets into a combined SeqData object\n",
    "sdata_combined_raw = eu.dl.concat([sdata_leaf_raw, sdata_proto_raw], keys=[\"leaf\", \"proto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw versions of these three\n",
    "sdata_leaf_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"leaf_raw.h5sd\"))\n",
    "sdata_proto_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"proto_raw.h5sd\"))\n",
    "sdata_combined_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"combined_raw.h5sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the input data in the combined SeqData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\trev_seqs: None -> 147966 rev_seqs added\n",
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 147966 ohe_seqs added\n",
      "\tohe_rev_seqs: None -> 147966 ohe_rev_seqs added\n"
     ]
    }
   ],
   "source": [
    "# Add reverse complement sequences and one-hot encoded sequences (forward and reverse complement)\n",
    "eu.pp.reverse_complement_data(sdata_combined_raw)\n",
    "eu.pp.one_hot_encode_data(sdata_combined_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata_combined_raw.ohe_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_combined_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"combined_processed.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each of the three datases into training and train sets\n",
    "sdata_leaf_train = sdata_leaf_raw[sdata_leaf_raw[\"set\"] == \"train\"]\n",
    "sdata_proto_train = sdata_proto_raw[sdata_proto_raw[\"set\"] == \"train\"]\n",
    "sdata_combined_train = sdata_combined_raw[sdata_combined_raw[\"set\"] == \"train\"]\n",
    "sdata_leaf_test = sdata_leaf_raw[sdata_leaf_raw[\"set\"] == \"test\"]\n",
    "sdata_proto_test = sdata_proto_raw[sdata_proto_raw[\"set\"] == \"test\"]\n",
    "sdata_combined_test = sdata_combined_raw[sdata_combined_raw[\"set\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdata_leaf_train.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"leaf_processed_train.h5sd\"))\n",
    "sdata_proto_train.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"proto_processed_train.h5sd\"))\n",
    "sdata_combined_train.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"combined_processed_train.h5sd\"))\n",
    "sdata_leaf_test.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"leaf_processed_test.h5sd\"))\n",
    "sdata_proto_test.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"proto_processed_test.h5sd\"))\n",
    "sdata_combined_test.write_h5sd(os.path.join(eu.settings.dataset_dir, \"jores21\", \"combined_processed_test.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
