{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661f6b58",
   "metadata": {},
   "source": [
    "# Testing `ResidualBind` model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64213c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Authorship:**\n",
    "Adam Klie, *11/05/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook for testing out the custom `ResidualBind` model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import splev\n",
    "\n",
    "\n",
    "def bs(x, df=None, knots=None, degree=3, intercept=False):\n",
    "    \"\"\"\n",
    "    df : int\n",
    "        The number of degrees of freedom to use for this spline. The\n",
    "        return value will have this many columns. You must specify at least\n",
    "        one of `df` and `knots`.\n",
    "    knots : list(float)\n",
    "        The interior knots of the spline. If unspecified, then equally\n",
    "        spaced quantiles of the input data are used. You must specify at least\n",
    "        one of `df` and `knots`.\n",
    "    degree : int\n",
    "        The degree of the piecewise polynomial. Default is 3 for cubic splines.\n",
    "    intercept : bool\n",
    "        If `True`, the resulting spline basis will span the intercept term\n",
    "        (i.e. the constant function). If `False` (the default) then this\n",
    "        will not be the case, which is useful for avoiding overspecification\n",
    "        in models that include multiple spline terms and/or an intercept term.\n",
    "    \"\"\"\n",
    "\n",
    "    order = degree + 1\n",
    "    inner_knots = []\n",
    "    if df is not None and knots is None:\n",
    "        n_inner_knots = df - order + (1 - intercept)\n",
    "        if n_inner_knots < 0:\n",
    "            n_inner_knots = 0\n",
    "            print(\"df was too small; have used %d\"\n",
    "                  % (order - (1 - intercept)))\n",
    "\n",
    "        if n_inner_knots > 0:\n",
    "            inner_knots = np.percentile(\n",
    "                x, 100 * np.linspace(0, 1, n_inner_knots + 2)[1:-1])\n",
    "\n",
    "    elif knots is not None:\n",
    "        inner_knots = knots\n",
    "\n",
    "    all_knots = np.concatenate(\n",
    "        ([np.min(x), np.max(x)] * order, inner_knots))\n",
    "\n",
    "    all_knots.sort()\n",
    "\n",
    "    n_basis = len(all_knots) - (degree + 1)\n",
    "    basis = np.empty((x.shape[0], n_basis), dtype=float)\n",
    "\n",
    "    for i in range(n_basis):\n",
    "        coefs = np.zeros((n_basis,))\n",
    "        coefs[i] = 1\n",
    "        basis[:, i] = splev(x, (all_knots, coefs, degree))\n",
    "\n",
    "    if not intercept:\n",
    "        basis = basis[:, 1:]\n",
    "    return basis\n",
    "\n",
    "\n",
    "def spline_factory(n, df, log=False):\n",
    "    if log:\n",
    "        dist = np.array(np.arange(n) - n/2.0)\n",
    "        dist = np.log(np.abs(dist) + 1) * ( 2*(dist>0)-1)\n",
    "        n_knots = df - 4\n",
    "        knots = np.linspace(np.min(dist),np.max(dist),n_knots+2)[1:-1]\n",
    "        return torch.from_numpy(bs(\n",
    "            dist, knots=knots, intercept=True)).float()\n",
    "    else:\n",
    "        dist = np.arange(n)\n",
    "        return torch.from_numpy(bs(\n",
    "            dist, df=df, intercept=True)).float()\n",
    "\n",
    "\n",
    "\n",
    "class BSplineTransformation(nn.Module):\n",
    "\n",
    "    def __init__(self, degrees_of_freedom, log=False, scaled=False):\n",
    "        super(BSplineTransformation, self).__init__()\n",
    "        self._spline_tr = None\n",
    "        self._log = log\n",
    "        self._scaled = scaled\n",
    "        self._df = degrees_of_freedom\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self._spline_tr is None:\n",
    "            spatial_dim = input.size()[-1]\n",
    "            self._spline_tr = spline_factory(spatial_dim, self._df, log=self._log)\n",
    "            if self._scaled:\n",
    "                self._spline_tr = self._spline_tr / spatial_dim\n",
    "            if input.is_cuda:\n",
    "                self._spline_tr = self._spline_tr.cuda()\n",
    "        \n",
    "        return  torch.matmul(input, self._spline_tr)\n",
    "\n",
    "\n",
    "\n",
    "class BSplineConv1D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, degrees_of_freedom, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True, log=False, scaled = True):\n",
    "        super(BSplineConv1D, self).__init__()\n",
    "        self._df = degrees_of_freedom\n",
    "        self._log = log\n",
    "        self._scaled = scaled\n",
    "\n",
    "        self.spline = nn.Conv1d(1, degrees_of_freedom, kernel_size, stride, padding, dilation,\n",
    "            bias=False)\n",
    "        self.spline.weight = spline_factory(kernel_size, self._df, log=log).view(self._df, 1, kernel_size)\n",
    "        if scaled:\n",
    "            self.spline.weight = self.spline.weight / kernel_size            \n",
    "        self.spline.weight = nn.Parameter(self.spline.weight)\n",
    "        self.spline.weight.requires_grad = False\n",
    "        self.conv1d = nn.Conv1d(in_channels * degrees_of_freedom, out_channels, 1, \n",
    "            groups = groups, bias=bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, n_channels, length = input.size()\n",
    "        spline_out = self.spline(input.view(batch_size * n_channels,1,length))\n",
    "        conv1d_out = self.conv1d(spline_out.view(batch_size, n_channels * self._df,  length))\n",
    "        return conv1d_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Sei framework\n",
    "class Sei(nn.Module):\n",
    "    def __init__(self, sequence_length=4096, n_genomic_features=21907):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sequence_length : int\n",
    "        n_genomic_features : int\n",
    "        \"\"\"\n",
    "        super(Sei, self).__init__()\n",
    "\n",
    "        self.lconv1 = nn.Sequential(\n",
    "            nn.Conv1d(4, 480, kernel_size=9, padding=4),\n",
    "            nn.Conv1d(480, 480, kernel_size=9, padding=4))\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(480, 480, kernel_size=9, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(480, 480, kernel_size=9, padding=4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.lconv2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(480, 640, kernel_size=9, padding=4),\n",
    "            nn.Conv1d(640, 640, kernel_size=9, padding=4))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(640, 640, kernel_size=9,padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(640, 640, kernel_size=9,padding=4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.lconv3 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(640, 960, kernel_size=9, padding=4),\n",
    "            nn.Conv1d(960, 960, kernel_size=9, padding=4))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(960, 960, kernel_size=9,padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(960, 960, kernel_size=9,padding=4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.dconv1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.10),\n",
    "            nn.Conv1d(960, 960, kernel_size=5, dilation=2, padding=4),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dconv2 = nn.Sequential(\n",
    "            nn.Dropout(p=0.10),\n",
    "            nn.Conv1d(960, 960, kernel_size=5, dilation=4, padding=8),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dconv3 = nn.Sequential(\n",
    "            nn.Dropout(p=0.10),\n",
    "            nn.Conv1d(960, 960, kernel_size=5, dilation=8, padding=16),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dconv4 = nn.Sequential(\n",
    "            nn.Dropout(p=0.10),\n",
    "            nn.Conv1d(960, 960, kernel_size=5, dilation=16, padding=32),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dconv5 = nn.Sequential(\n",
    "            nn.Dropout(p=0.10),\n",
    "            nn.Conv1d(960, 960, kernel_size=5, dilation=25, padding=50),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self._spline_df = int(128/8)        \n",
    "        self.spline_tr = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            BSplineTransformation(self._spline_df, scaled=False))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(960 * self._spline_df, n_genomic_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_genomic_features, n_genomic_features),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward propagation of a batch.\n",
    "        \"\"\"\n",
    "        lout1 = self.lconv1(x)\n",
    "        out1 = self.conv1(lout1)\n",
    "\n",
    "        lout2 = self.lconv2(out1 + lout1)\n",
    "        out2 = self.conv2(lout2)\n",
    "\n",
    "        lout3 = self.lconv3(out2 + lout2)\n",
    "        out3 = self.conv3(lout3)\n",
    "\n",
    "        dconv_out1 = self.dconv1(out3 + lout3)\n",
    "        cat_out1 = out3 + dconv_out1\n",
    "        dconv_out2 = self.dconv2(cat_out1)\n",
    "        cat_out2 = cat_out1 + dconv_out2\n",
    "        dconv_out3 = self.dconv3(cat_out2)\n",
    "        cat_out3 = cat_out2 + dconv_out3\n",
    "        dconv_out4 = self.dconv4(cat_out3)\n",
    "        cat_out4 = cat_out3 + dconv_out4\n",
    "        dconv_out5 = self.dconv5(cat_out4)\n",
    "        out = cat_out4 + dconv_out5\n",
    "        \n",
    "        spline_out = self.spline_tr(out)\n",
    "        reshape_out = spline_out.view(spline_out.size(0), 960 * self._spline_df)\n",
    "        predict = self.classifier(reshape_out)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Basset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5405, 0.4398],\n",
       "        [0.6291, 0.5908],\n",
       "        [0.5014, 0.6883],\n",
       "        [0.3922, 0.7281],\n",
       "        [0.5423, 0.5404],\n",
       "        [0.4932, 0.5351],\n",
       "        [0.5355, 0.4664],\n",
       "        [0.4262, 0.4420],\n",
       "        [0.4865, 0.6399],\n",
       "        [0.4958, 0.5314]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 4, 100)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b89b94102a47d3a29709cf5f5a8de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "One-hot encoding sequences:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "\tohe_seqs: None -> 1000 ohe_seqs added\n",
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + train_val\n"
     ]
    }
   ],
   "source": [
    "sdata = eu.datasets.random1000()\n",
    "eu.pp.ohe_seqs_sdata(sdata)\n",
    "eu.pp.train_test_split_sdata(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n",
      "Missing logger folder: /workspaces/EUGENe/tests/notebooks/implement/models/eugene_logs/ssResidualBind_regression\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type                      | Params\n",
      "-------------------------------------------------------------\n",
      "0 | hp_metric      | R2Score                   | 0     \n",
      "1 | conv           | BasicConv1D               | 4.5 K \n",
      "2 | residual_block | ResidualModule            | 83.8 K\n",
      "3 | average_pool   | AvgPool1d                 | 0     \n",
      "4 | dropout        | Dropout                   | 0     \n",
      "5 | flatten        | Flatten                   | 0     \n",
      "6 | fc             | BasicFullyConnectedModule | 2.0 M \n",
      "-------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.320     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15103dc447749308845d19db0efb48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 13\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/vscode/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be41c66e0c334c92a7ae592ab87011c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a7e9ff522f4e0c9760a547f1ca3254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eu.train.fit(model, sdata, target_keys=\"activity_0\", epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
